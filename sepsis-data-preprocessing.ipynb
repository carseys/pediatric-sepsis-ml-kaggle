{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readin_data(data_type: str):\n",
    "    \"\"\" This function reads in test or train data, which must be in folders 'testing_data' and 'training_data' in the same directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_type' : str\n",
    "        This must be 'test' or 'train'.\n",
    "    \"\"\"\n",
    "    assert (data_type=='test') or (data_type=='train'), f'You gave data_type as {data_type}. Please define data_type as \"test\" or \"train.\"'\n",
    "    if data_type == 'test':\n",
    "        inner_directory = './testing_data/'\n",
    "        data_list = os.listdir('./testing_data')\n",
    "    else:\n",
    "        inner_directory = './training_data/'\n",
    "        data_list = os.listdir('./training_data')\n",
    "    data_dict = {}\n",
    "    for file_name in data_list:\n",
    "        data_dict[file_name.split('.')[0]] = pd.read_csv(inner_directory+file_name).drop_duplicates()\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_data_directory():\n",
    "    \"\"\" Makes 'processed_data' directory if one is not found.\n",
    "    \"\"\"\n",
    "    os.makedirs('./processed_data', exist_ok=True)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_uids(data_dictionary: dict):\n",
    "    \"\"\" This function adds a UID to each row to establish unique instances between person_id & measurement datetimes for the various tables.\n",
    "    \n",
    "    This is not done for the demographics file since the information in it is not sensitive to the hour.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    print(\"Adding UIDs.\")\n",
    "\n",
    "    for table_ind in list(data_dictionary.keys()):\n",
    "        if not table_ind.startswith(\"person_demographics\"):\n",
    "            table = data_dictionary[table_ind]\n",
    "            datetime_index = np.argmax([i.find('datetime') for i in table.columns])\n",
    "            date_column = table.columns[datetime_index]\n",
    "            personid_index = np.argmax([i.find('person_id') for i in table.columns])\n",
    "            personid_column = table.columns[personid_index]\n",
    "            table['uid'] = table[date_column].astype(str) + table[personid_column].astype(str)\n",
    "            table.drop(columns=[date_column,personid_column],inplace=True)\n",
    "            data_dictionary[table_ind] = table\n",
    "            # print(f'file {table_ind} with len {len(table)}')\n",
    "    \n",
    "    print(\"UIDs added\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birthday_management(data_dictionary: dict):\n",
    "    \"\"\"\n",
    "    This function processes the 'person_demographics' table of given data, which is inputed as a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    demographics_ind_no = np.argmax([table.startswith(\"person_demographics\") for table in data_dictionary.keys()])\n",
    "    demographics_index = list(data_dictionary.keys())[demographics_ind_no]\n",
    "    demographics = data_dictionary[demographics_index]\n",
    "    print(f\"Beginning processing for {demographics_index}.\")\n",
    "    \n",
    "\n",
    "    new_birthday_col = pd.DataFrame(columns=['birthday_formatted', 'person_id'])\n",
    "    new_visit_col = pd.DataFrame(columns=['visit_start_date','new_visit_startdate'])\n",
    "    \n",
    "    for person in np.unique(demographics['person_id']):\n",
    "        birthday = demographics[demographics['person_id']==person]['birth_datetime'].to_list()[0]\n",
    "        birthday_formatted = datetime.strptime(birthday,'%Y-%m-%d')\n",
    "        new_birthday_col.loc[len(new_birthday_col)] = [birthday_formatted, person]\n",
    "\n",
    "    for date in np.unique(demographics['visit_start_date']):\n",
    "        visit_start = demographics[demographics['visit_start_date']==date]['visit_start_date'].to_list()[0]\n",
    "        new_visit_startdate = datetime.strptime(visit_start,'%Y-%m-%d')\n",
    "        # print(f'new {new_visit_startdate} old {date}')\n",
    "        new_visit_col.loc[len(new_visit_col)] = [date, new_visit_startdate]\n",
    "\n",
    "\n",
    "    demographics = pd.merge(left=demographics,right=new_birthday_col,how='left',on='person_id')\n",
    "    demographics = pd.merge(left=demographics,right=new_visit_col,how='left',on='visit_start_date')\n",
    "    demographics.drop(columns=['visit_start_date','birth_datetime'],inplace=True)\n",
    "    demographics.to_csv(f'./processed_data/processed_{demographics_index}.csv')\n",
    "    data_dictionary[demographics_index] = demographics\n",
    "    print(f\"Finished processing of {demographics_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_meds_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'measurement_meds' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    body_measurements_ind = np.argmax([table.startswith(\"measurement_meds\") for table in data_dictionary.keys()])\n",
    "    body_measurements_index = list(data_dictionary.keys())[body_measurements_ind]\n",
    "    measurements = data_dictionary[body_measurements_index]\n",
    "    print(f\"Beginning processing for {body_measurements_index}.\")\n",
    "\n",
    "    \n",
    "    measurements = measurements.dropna(subset=measurements.select_dtypes(float).columns, how='all')\n",
    "    # measurements.drop(index=[i for i in measurements[measurements['Body temperature']>45].index], axis=1,inplace=True)\n",
    "    measurements['Body temperature'] = measurements['Body temperature'].apply(lambda x: np.nan if x > 46 else x)\n",
    "    measurements.to_csv(f'./processed_data/processed_{body_measurements_index}.csv')\n",
    "    data_dictionary[body_measurements_index] = measurements\n",
    "    print(f\"Finished processing of {body_measurements_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drugs_exposure_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'drugsexposure' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    You need to run add_uids first.\n",
    "    \"\"\"\n",
    "    # assert uids_added == True, 'You need to run add_uids before this function.'\n",
    "    drugs_exposure_ind = np.argmax([table.startswith(\"drugsexposure\") for table in data_dictionary.keys()])\n",
    "    drugs_exposure_index = list(data_dictionary.keys())[drugs_exposure_ind]\n",
    "    drugs_exposure = data_dictionary[drugs_exposure_index]\n",
    "    print(f\"Beginning processing for {drugs_exposure_index}.\")\n",
    "\n",
    "    drugs_exposure_processed = pd.DataFrame(columns = ['uid', 'drugs', 'routes', 'visit_occurrence_id'])\n",
    "    \n",
    "    for x in tqdm(np.unique(drugs_exposure['uid'])):\n",
    "        drugs = drugs_exposure[drugs_exposure['uid']==x]['drug_concept_id'].to_list()\n",
    "        drugs.sort()\n",
    "        try:\n",
    "            route = drugs_exposure[drugs_exposure['uid']==x]['route_concept_id'].to_list()\n",
    "            route = list(set(route))\n",
    "            route = [str(i) for i in route]\n",
    "            route.sort()\n",
    "        except:\n",
    "            route = drugs_exposure[drugs_exposure['uid']==x]['route_concept_id'].to_list()\n",
    "            route = list(set(route))\n",
    "        visit_occurrence = drugs_exposure[drugs_exposure['uid']==x]['visit_occurrence_id'].to_list()[0]\n",
    "        drugs_exposure_processed.loc[len(drugs_exposure_processed)]= [x,drugs,route, visit_occurrence]\n",
    "    # switching format from list to string for later processing of categorical data:\n",
    "    for row in drugs_exposure_processed['drugs']:\n",
    "        row = str(row)[1:-1]\n",
    "    for row in drugs_exposure_processed['routes']:\n",
    "        row = str(row)[1:-1]\n",
    "\n",
    "    drugs_exposure_processed['drugs'] = drugs_exposure_processed['drugs'].apply(lambda x: str(x)[1:-1])\n",
    "    drugs_exposure_processed['drugs'] = drugs_exposure_processed['drugs'].apply(lambda x: np.nan if x=='a' else x)\n",
    "\n",
    "\n",
    "    drugs_exposure_processed['routes'] = drugs_exposure_processed['routes'].apply(lambda x: np.nan if x is str else str(x)[1:-1])\n",
    "    drugs_exposure_processed['routes'] = drugs_exposure_processed['routes'].apply(lambda x: np.nan if x=='a' else x)\n",
    "\n",
    "    data_dictionary[drugs_exposure_index] = drugs_exposure_processed\n",
    "\n",
    "\n",
    "    # drugs_exposure.to_csv(f'./processed_data/processed_{drugs_exposure_index}.csv')\n",
    "    print(f\"Finished processing of {drugs_exposure_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_lab_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'measurement_lab' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    You need to run add_uids first.\n",
    "    \"\"\"\n",
    "    # assert uids_added == True, 'You need to run add_uids before this function.'\n",
    "\n",
    "    measurement_lab_ind = np.argmax([table.startswith(\"measurement_lab\") for table in data_dictionary.keys()])\n",
    "    measurement_lab_index = list(data_dictionary.keys())[measurement_lab_ind]\n",
    "    measurement_lab = data_dictionary[measurement_lab_index]\n",
    "    print(f\"Beginning processing for {measurement_lab_index}.\")\n",
    "\n",
    "    nan_col_inds = list(measurement_lab.isna().all())\n",
    "    nan_col_indices = list(measurement_lab.loc[:,nan_col_inds].columns)\n",
    "    measurement_lab.drop(columns=nan_col_indices, inplace=True)\n",
    "\n",
    "    measurement_lab = measurement_lab.dropna(subset=list(measurement_lab.select_dtypes(float).columns), how='all')\n",
    "    measurement_lab_count = pd.DataFrame([list(i) for i in Counter(measurement_lab['uid']).items()],columns=['uid','count'])\n",
    "    measurement_lab_count['count'].astype(int)\n",
    "    measurement_lab_rows = pd.DataFrame()\n",
    "    measurement_lab_extras = measurement_lab_count[measurement_lab_count['count']>1]\n",
    "    for j in [i for i in measurement_lab_extras['uid']]:\n",
    "        measurement_lab_rows = pd.concat([measurement_lab_rows,measurement_lab[measurement_lab['uid']==j].max().to_frame().T]).reset_index(drop=True)\n",
    "    measurement_lab = measurement_lab.drop(index=[i for i in measurement_lab[measurement_lab['uid']==measurement_lab_extras['uid'].item()].index], axis=1,inplace=False)\n",
    "    measurement_lab = pd.concat([measurement_lab,measurement_lab_rows]).reset_index(drop=True)\n",
    "\n",
    "    col_inds = [not((i.endswith('_id')) or (i=='uid')) for i in list(measurement_lab.columns)]\n",
    "    col_names = measurement_lab.columns.values[col_inds]\n",
    "    for column in col_names:\n",
    "        measurement_lab[column] = measurement_lab[column].astype(float)\n",
    "\n",
    "    measurement_lab.to_csv(f'./processed_data/processed_{measurement_lab_index}.csv')\n",
    "    data_dictionary[measurement_lab_index] = measurement_lab\n",
    "    print(f\"Finished processing of {measurement_lab_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_observation_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'measurement_observation' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    measurement_obs_ind = np.argmax([table.startswith(\"measurement_observation\") for table in data_dictionary.keys()])\n",
    "    measurement_obs_index = list(data_dictionary.keys())[measurement_obs_ind]\n",
    "    measurement_obs = data_dictionary[measurement_obs_index]\n",
    "    print(f\"Beginning processing for {measurement_obs_index}.\")\n",
    "\n",
    "    # measurement_obs = measurement_obs.dropna(subset=measurement_obs.select_dtypes(float).columns, how='all')\n",
    "    measurement_obs.to_csv(f'./processed_data/processed_{measurement_obs_index}.csv')\n",
    "    data_dictionary[measurement_obs_index] = measurement_obs\n",
    "    print(f\"Finished processing of {measurement_obs_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'observation' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    observation_ind = np.argmax([table.startswith(\"observation\") for table in data_dictionary.keys()])\n",
    "    observation_index = list(data_dictionary.keys())[observation_ind]\n",
    "    observation = data_dictionary[observation_index]\n",
    "    print(f\"Beginning processing for {observation_index}.\")\n",
    "\n",
    "\n",
    "    observation = observation.dropna(subset=observation.select_dtypes(object).columns, how='all')\n",
    "\n",
    "    observation.to_csv(f'./processed_data/processed_{observation_index}.csv')\n",
    "\n",
    "    data_dictionary[observation_index] = observation \n",
    "    print(f\"Finished processing of {observation_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedures_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'observation' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    You need to run add_uids first.\n",
    "    \"\"\"\n",
    "    # assert uids_added == True, 'You need to run add_uids before this function.'\n",
    "\n",
    "    procedures_ind = np.argmax([table.startswith(\"proceduresoccurrences\") for table in data_dictionary.keys()])\n",
    "    procedures_index = list(data_dictionary.keys())[procedures_ind]\n",
    "    procedures = data_dictionary[procedures_index]\n",
    "    print(f\"Beginning processing for {procedures_index}.\")\n",
    "\n",
    "    procedures = procedures.dropna(subset=procedures.select_dtypes(object).columns, how='all')\n",
    "\n",
    "\n",
    "    visit_id_index = np.argmax([i.find('visit_occurrence') for i in procedures.columns])\n",
    "    visit_column = procedures.columns[visit_id_index]\n",
    "    procedures.drop(columns=visit_column,inplace=True)\n",
    "    procedures.drop_duplicates(inplace=True)\n",
    "\n",
    "    procedures.to_csv(f'./processed_data/processed_{procedures_index}.csv')\n",
    "\n",
    "\n",
    "    data_dictionary[procedures_index] = procedures \n",
    "    print(f\"Finished processing of {procedures_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devices_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'devices' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    devices_ind = np.argmax([table.startswith(\"devices\") for table in data_dictionary.keys()])\n",
    "    devices_index = list(data_dictionary.keys())[devices_ind]\n",
    "    devices = data_dictionary[devices_index]\n",
    "    print(f\"Beginning processing for {devices_index}.\")\n",
    "\n",
    "    devices = devices.dropna(subset=devices.select_dtypes(object).columns, how='all')\n",
    "\n",
    "    devices.to_csv(f'./processed_data/processed_{devices_index}.csv')\n",
    "\n",
    "    data_dictionary[devices_index] = devices\n",
    "    print(f\"Finished processing of {devices_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepsis_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'sepsis' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    sepsis_ind = np.argmax([table.startswith(\"SepsisLabel\") for table in data_dictionary.keys()])\n",
    "    sepsis_index = list(data_dictionary.keys())[sepsis_ind]\n",
    "    sepsis = data_dictionary[sepsis_index]\n",
    "    print(f\"Beginning processing for {sepsis_index}.\")\n",
    "\n",
    "    #no NA values found:\n",
    "    sepsis = sepsis.dropna(subset=sepsis.select_dtypes(int).columns, how='all')\n",
    "    no_time_rows = list(sepsis.loc[sepsis['uid'].str.startswith('nan', na=False)].index)\n",
    "    sepsis = sepsis.drop(index=no_time_rows, axis = 1, inplace = False)\n",
    "\n",
    "    print(f\"Finished processing of {sepsis_index}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_type: str, load_tables: str):\n",
    "    \"\"\" This function reads in test or train data and goes through functions to preprocess it. For further details see specific functions.\n",
    "\n",
    "    Processed tables will be saved into the /processed folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_type' : str\n",
    "        This must be 'test' or 'train'. Determines which data to process.\n",
    "    'load_tables' : str\n",
    "        This must be 'yes' or 'no'. 'yes' means load csvs from processed_data folder. 'no' means process data from training or testing folder, depending on 'data_type' input given.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    'processed_data' : dict\n",
    "        This is a dictionary of datatables that have been processed\n",
    "    'factors' : DataFrame\n",
    "        This is a DataFrame of the data from 'processed_data' joined together.\n",
    "    \"\"\"\n",
    "    assert (data_type=='test') or (data_type=='train'), f'You gave data_type as {data_type}. Please define data_type as \"test\" or \"train.\"'\n",
    "    assert (load_tables=='yes') or (load_tables=='no'), f'You gave load_tables as {load_tables}. Please define load_tables as \"test\" or \"train.\"'\n",
    "\n",
    "    if data_type == 'train':\n",
    "        if load_tables == 'no':\n",
    "            training_data = readin_data('train')\n",
    "            add_uids(training_data)\n",
    "            birthday_management(training_data)\n",
    "            measurement_meds_processing(training_data)\n",
    "            drugs_exposure_processing(training_data)\n",
    "            measurement_lab_processing(training_data)\n",
    "            procedures_processing(training_data)\n",
    "            observation_processing(training_data)\n",
    "            measurement_observation_processing(training_data)\n",
    "            devices_processing(training_data)\n",
    "            sepsis_processing(training_data)\n",
    "        else:\n",
    "            training_data={}\n",
    "            #fill in\n",
    "\n",
    "        factors = pd.merge(left=training_data['measurement_meds_train'], right=training_data['measurement_lab_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['drugsexposure_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['proceduresoccurrences_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['person_demographics_episode_train'], how='outer',on='visit_occurrence_id')\n",
    "        factors = pd.merge(left=training_data['SepsisLabel_train'],right=factors,how='left',on='uid')\n",
    "        factors.to_csv(f'./processed_data/factors_train.csv')\n",
    "        processed_data = training_data\n",
    "\n",
    "    else:\n",
    "        if load_tables == 'no':\n",
    "            testing_data = readin_data('test')\n",
    "            add_uids(testing_data)\n",
    "            birthday_management(testing_data)\n",
    "            measurement_meds_processing(testing_data)\n",
    "            drugs_exposure_processing(testing_data)\n",
    "            measurement_lab_processing(testing_data)\n",
    "            procedures_processing(testing_data)\n",
    "            observation_processing(testing_data)\n",
    "            measurement_observation_processing(testing_data)\n",
    "            devices_processing(testing_data)\n",
    "            sepsis_processing(testing_data)\n",
    "        else:\n",
    "            #fill in\n",
    "            testing_data = {}\n",
    "\n",
    "        factors = pd.merge(left=testing_data['measurement_meds_test'], right=testing_data['measurement_lab_test'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=testing_data['drugsexposure_test'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=testing_data['person_demographics_episode_test'], how='outer',on='visit_occurrence_id')\n",
    "        factors = pd.merge(left=testing_data['SepsisLabel_test'],right=factors,how='left',on='uid')\n",
    "        factors.to_csv(f'./processed_data/factors_test.csv')\n",
    "        processed_data = testing_data\n",
    "\n",
    "    factors.drop(columns=['visit_occurrence_id_x','visit_occurrence_id_y'],inplace=True)\n",
    "\n",
    "    return processed_data, factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding UIDs.\n",
      "UIDs added\n",
      "Beginning processing for person_demographics_episode_train.\n",
      "Finished processing of person_demographics_episode_train.\n",
      "Beginning processing for measurement_meds_train.\n",
      "Finished processing of measurement_meds_train.\n",
      "Beginning processing for drugsexposure_train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150407/150407 [2:33:33<00:00, 16.33it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing of drugsexposure_train.\n",
      "Beginning processing for measurement_lab_train.\n",
      "Finished processing of measurement_lab_train.\n",
      "Beginning processing for proceduresoccurrences_train.\n",
      "Finished processing of proceduresoccurrences_train.\n",
      "Beginning processing for observation_train.\n",
      "Finished processing of observation_train.\n",
      "Beginning processing for measurement_observation_train.\n",
      "Finished processing of measurement_observation_train.\n",
      "Beginning processing for devices_train.\n",
      "Finished processing of devices_train.\n",
      "Beginning processing for SepsisLabel_train.\n",
      "Finished processing of SepsisLabel_train.\n"
     ]
    }
   ],
   "source": [
    "training_data, data_factors = process_data(data_type='train', load_tables='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(data_directory: dict, data_type: str):\n",
    "    \"\"\" This function takes a data dictionary of tables and merges to have a table of factors for categorical encoding etc.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_directory' : dict\n",
    "        This is a data dictionary of pandas DataFrames.\n",
    "    'data_type' : str\n",
    "        This must be 'test' or 'train'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    'factors' : DataFrame\n",
    "        This is a DataFrame of the data from 'processed_data' joined together.    \n",
    "    \"\"\"\n",
    "    assert (data_type=='test') or (data_type=='train'), f'You gave data_type as {data_type}. Please define data_type as \"test\" or \"train.\"'\n",
    "\n",
    "    if data_type == 'train':\n",
    "        training_data = data_directory.copy()\n",
    "\n",
    "        factors = pd.merge(left=training_data['measurement_meds_train'], right=training_data['measurement_lab_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['drugsexposure_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['proceduresoccurrences_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['person_demographics_episode_train'], how='outer',on='visit_occurrence_id')\n",
    "        factors = pd.merge(left=training_data['SepsisLabel_train'],right=factors,how='left',on='uid')\n",
    "\n",
    "    else:\n",
    "        testing_data = data_directory.copy()\n",
    "\n",
    "        factors = pd.merge(left=testing_data['measurement_meds_test'], right=testing_data['measurement_lab_test'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=testing_data['drugsexposure_test'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=testing_data['person_demographics_episode_test'], how='outer',on='visit_occurrence_id')\n",
    "        factors = pd.merge(left=testing_data['SepsisLabel_test'],right=factors,how='left',on='uid')\n",
    "\n",
    "    factors.to_csv(f'./processed_data/processed_{factors}.csv')\n",
    "\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factors_2 = data_factors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 331642 entries, 0 to 331641\n",
      "Data columns (total 54 columns):\n",
      " #   Column                                               Non-Null Count   Dtype         \n",
      "---  ------                                               --------------   -----         \n",
      " 0   SepsisLabel                                          331642 non-null  int64         \n",
      " 1   uid                                                  331642 non-null  object        \n",
      " 2   Systolic blood pressure                              38380 non-null   float64       \n",
      " 3   Diastolic blood pressure                             38367 non-null   float64       \n",
      " 4   Body temperature                                     198709 non-null  float64       \n",
      " 5   Respiratory rate                                     79352 non-null   float64       \n",
      " 6   Heart rate                                           92769 non-null   float64       \n",
      " 7   Measurement of oxygen saturation at periphery        92613 non-null   float64       \n",
      " 8   Oxygen/Gas total [Pure volume fraction] Inhaled gas  2043 non-null    float64       \n",
      " 9   Base excess in Venous blood by calculation           19054 non-null   float64       \n",
      " 10  Base excess in Arterial blood by calculation         2413 non-null    float64       \n",
      " 11  Phosphate [Moles/volume] in Serum or Plasma          10056 non-null   float64       \n",
      " 12  Potassium [Moles/volume] in Blood                    31660 non-null   float64       \n",
      " 13  Bilirubin.total [Moles/volume] in Serum or Plasma    14595 non-null   float64       \n",
      " 14  Neutrophil Ab [Units/volume] in Serum                24638 non-null   float64       \n",
      " 15  Bicarbonate [Moles/volume] in Arterial blood         2413 non-null    float64       \n",
      " 16  Hematocrit [Volume Fraction] of Blood                27697 non-null   float64       \n",
      " 17  Glucose [Moles/volume] in Serum or Plasma            16326 non-null   float64       \n",
      " 18  Calcium [Moles/volume] in Serum or Plasma            8349 non-null    float64       \n",
      " 19  Chloride [Moles/volume] in Blood                     32508 non-null   float64       \n",
      " 20  Sodium [Moles/volume] in Serum or Plasma             32456 non-null   float64       \n",
      " 21  C reactive protein [Mass/volume] in Serum or Plasma  22914 non-null   float64       \n",
      " 22  Carbon dioxide [Partial pressure] in Venous blood    19056 non-null   float64       \n",
      " 23  Oxygen [Partial pressure] in Venous blood            21382 non-null   float64       \n",
      " 24  Albumin [Mass/volume] in Serum or Plasma             12580 non-null   float64       \n",
      " 25  Bicarbonate [Moles/volume] in Venous blood           21417 non-null   float64       \n",
      " 26  Oxygen [Partial pressure] in Arterial blood          2412 non-null    float64       \n",
      " 27  Carbon dioxide [Partial pressure] in Arterial blood  2413 non-null    float64       \n",
      " 28  Interleukin 6 [Mass/volume] in Body fluid            60 non-null      float64       \n",
      " 29  Magnesium [Moles/volume] in Blood                    11477 non-null   float64       \n",
      " 30  Prothrombin time (PT)                                7808 non-null    float64       \n",
      " 31  Procalcitonin [Mass/volume] in Serum or Plasma       12580 non-null   float64       \n",
      " 32  Lactate [Moles/volume] in Blood                      19827 non-null   float64       \n",
      " 33  Creatinine [Mass/volume] in Blood                    25850 non-null   float64       \n",
      " 34  Fibrinogen measurement                               7756 non-null    float64       \n",
      " 35  Bilirubin measurement                                11401 non-null   float64       \n",
      " 36  Partial thromboplastin time                          7757 non-null    float64       \n",
      " 37   activated                                           24786 non-null   float64       \n",
      " 38  Total white blood count                              24728 non-null   float64       \n",
      " 39  Platelet count                                       6360 non-null    float64       \n",
      " 40  White blood cell count                               21635 non-null   float64       \n",
      " 41  Blood venous pH                                      367 non-null     float64       \n",
      " 42  D-dimer level                                        2415 non-null    float64       \n",
      " 43  Blood arterial pH                                    27082 non-null   float64       \n",
      " 44  Hemoglobin [Moles/volume] in Blood                   24590 non-null   float64       \n",
      " 45  drugs                                                331642 non-null  object        \n",
      " 46  routes                                               331642 non-null  object        \n",
      " 47  visit_occurrence_id                                  66443 non-null   float64       \n",
      " 48  procedure                                            195517 non-null  object        \n",
      " 49  person_id                                            66443 non-null   float64       \n",
      " 50  age_in_months                                        66443 non-null   float64       \n",
      " 51  gender                                               66443 non-null   object        \n",
      " 52  birthday_formatted                                   66443 non-null   datetime64[ns]\n",
      " 53  new_visit_startdate                                  66443 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(46), int64(1), object(5)\n",
      "memory usage: 136.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_factors_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_2 = training_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_meas_lab(data_dictionary: dict):\n",
    "    measurement_lab_ind = np.argmax([table.startswith(\"measurement_lab\") for table in data_dictionary.keys()])\n",
    "    measurement_lab_index = list(data_dictionary.keys())[measurement_lab_ind]\n",
    "    measurement_lab = data_dictionary[measurement_lab_index]\n",
    "    col_inds = [not((i.endswith('_id')) or (i=='uid')) for i in list(training_data['measurement_lab_train'].columns)]\n",
    "    col_names = measurement_lab.columns.values[col_inds]\n",
    "    for column in col_names:\n",
    "        measurement_lab[column] = measurement_lab[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_drugs(df):\n",
    "    # df['drugs'].apply(lambda x: str(x) if pd.isna(x) else str(x)[1:-1])\n",
    "    df['routes'].apply(lambda x: str(x) if pd.isna(x) else str(x)[1:-1])\n",
    "    # drug_index = df.columns.get_loc('drugs')\n",
    "    # routes_index = df.columns.get_loc('routes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=331642, step=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_factors_2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factors_2['drugs'] = data_factors_2['drugs'].apply(lambda x: str(x)[1:-1])\n",
    "data_factors_2['drugs'] = data_factors_2['drugs'].apply(lambda x: 'NaN' if x=='a' else x)\n",
    "\n",
    "data_factors_2['routes'] = data_factors_2['routes'].apply(lambda x: 'NaN' if x is str else str(x)[1:-1])\n",
    "data_factors_2['routes'] = data_factors_2['routes'].apply(lambda x: 'NaN' if x=='a' else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'drugs', 'routes', 'procedure', 'gender'], dtype='object')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_factors_2.select_dtypes(object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_person_ids(df):\n",
    "    \"\"\"\n",
    "    This function reads person_id column for all rows based on UID and adds a new column with this information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'df': DataFrame\n",
    "        This should be a pandas dataframe which contains a column 'uid' with universal ids, with strings with format s.t. the person_id starts at the 18th index. e.g.: '2021-07-21 12:00:00623183219'\n",
    "    \"\"\"\n",
    "    # assert that uid column exists\n",
    "    new_person_id = pd.DataFrame(columns=['new_person_id'])\n",
    "    for row in tqdm(df['uid']):\n",
    "        new_id = row[19:]\n",
    "        new_person_id.loc[len(new_person_id)] = int(new_id)\n",
    "    df.drop(columns=['person_id'],inplace=True)\n",
    "    df['new_person_id'] = new_person_id\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nan459121546'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_factors_2['uid'][9334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>uid</th>\n",
       "      <th>Systolic blood pressure</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Body temperature</th>\n",
       "      <th>Respiratory rate</th>\n",
       "      <th>Heart rate</th>\n",
       "      <th>Measurement of oxygen saturation at periphery</th>\n",
       "      <th>Oxygen/Gas total [Pure volume fraction] Inhaled gas</th>\n",
       "      <th>Base excess in Venous blood by calculation</th>\n",
       "      <th>Base excess in Arterial blood by calculation</th>\n",
       "      <th>Phosphate [Moles/volume] in Serum or Plasma</th>\n",
       "      <th>Potassium [Moles/volume] in Blood</th>\n",
       "      <th>Bilirubin.total [Moles/volume] in Serum or Plasma</th>\n",
       "      <th>Neutrophil Ab [Units/volume] in Serum</th>\n",
       "      <th>Bicarbonate [Moles/volume] in Arterial blood</th>\n",
       "      <th>Hematocrit [Volume Fraction] of Blood</th>\n",
       "      <th>Glucose [Moles/volume] in Serum or Plasma</th>\n",
       "      <th>Calcium [Moles/volume] in Serum or Plasma</th>\n",
       "      <th>Chloride [Moles/volume] in Blood</th>\n",
       "      <th>Sodium [Moles/volume] in Serum or Plasma</th>\n",
       "      <th>C reactive protein [Mass/volume] in Serum or Plasma</th>\n",
       "      <th>Carbon dioxide [Partial pressure] in Venous blood</th>\n",
       "      <th>Oxygen [Partial pressure] in Venous blood</th>\n",
       "      <th>Albumin [Mass/volume] in Serum or Plasma</th>\n",
       "      <th>Bicarbonate [Moles/volume] in Venous blood</th>\n",
       "      <th>Oxygen [Partial pressure] in Arterial blood</th>\n",
       "      <th>Carbon dioxide [Partial pressure] in Arterial blood</th>\n",
       "      <th>Interleukin 6 [Mass/volume] in Body fluid</th>\n",
       "      <th>Magnesium [Moles/volume] in Blood</th>\n",
       "      <th>Prothrombin time (PT)</th>\n",
       "      <th>Procalcitonin [Mass/volume] in Serum or Plasma</th>\n",
       "      <th>Lactate [Moles/volume] in Blood</th>\n",
       "      <th>Creatinine [Mass/volume] in Blood</th>\n",
       "      <th>Fibrinogen measurement</th>\n",
       "      <th>Bilirubin measurement</th>\n",
       "      <th>Partial thromboplastin time</th>\n",
       "      <th>activated</th>\n",
       "      <th>Total white blood count</th>\n",
       "      <th>Platelet count</th>\n",
       "      <th>White blood cell count</th>\n",
       "      <th>Blood venous pH</th>\n",
       "      <th>D-dimer level</th>\n",
       "      <th>Blood arterial pH</th>\n",
       "      <th>Hemoglobin [Moles/volume] in Blood</th>\n",
       "      <th>drugs</th>\n",
       "      <th>routes</th>\n",
       "      <th>visit_occurrence_id</th>\n",
       "      <th>procedure</th>\n",
       "      <th>person_id</th>\n",
       "      <th>age_in_months</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthday_formatted</th>\n",
       "      <th>new_visit_startdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>0</td>\n",
       "      <td>nan459121546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SepsisLabel           uid  Systolic blood pressure  \\\n",
       "9334            0  nan459121546                      NaN   \n",
       "\n",
       "      Diastolic blood pressure  Body temperature  Respiratory rate  \\\n",
       "9334                       NaN               NaN               NaN   \n",
       "\n",
       "      Heart rate  Measurement of oxygen saturation at periphery  \\\n",
       "9334         NaN                                            NaN   \n",
       "\n",
       "      Oxygen/Gas total [Pure volume fraction] Inhaled gas  \\\n",
       "9334                                                NaN     \n",
       "\n",
       "      Base excess in Venous blood by calculation  \\\n",
       "9334                                         NaN   \n",
       "\n",
       "      Base excess in Arterial blood by calculation  \\\n",
       "9334                                           NaN   \n",
       "\n",
       "      Phosphate [Moles/volume] in Serum or Plasma  \\\n",
       "9334                                          NaN   \n",
       "\n",
       "      Potassium [Moles/volume] in Blood  \\\n",
       "9334                                NaN   \n",
       "\n",
       "      Bilirubin.total [Moles/volume] in Serum or Plasma  \\\n",
       "9334                                                NaN   \n",
       "\n",
       "      Neutrophil Ab [Units/volume] in Serum  \\\n",
       "9334                                    NaN   \n",
       "\n",
       "      Bicarbonate [Moles/volume] in Arterial blood  \\\n",
       "9334                                           NaN   \n",
       "\n",
       "      Hematocrit [Volume Fraction] of Blood  \\\n",
       "9334                                    NaN   \n",
       "\n",
       "      Glucose [Moles/volume] in Serum or Plasma  \\\n",
       "9334                                        NaN   \n",
       "\n",
       "      Calcium [Moles/volume] in Serum or Plasma  \\\n",
       "9334                                        NaN   \n",
       "\n",
       "      Chloride [Moles/volume] in Blood  \\\n",
       "9334                               NaN   \n",
       "\n",
       "      Sodium [Moles/volume] in Serum or Plasma  \\\n",
       "9334                                       NaN   \n",
       "\n",
       "      C reactive protein [Mass/volume] in Serum or Plasma  \\\n",
       "9334                                                NaN     \n",
       "\n",
       "      Carbon dioxide [Partial pressure] in Venous blood  \\\n",
       "9334                                                NaN   \n",
       "\n",
       "      Oxygen [Partial pressure] in Venous blood  \\\n",
       "9334                                        NaN   \n",
       "\n",
       "      Albumin [Mass/volume] in Serum or Plasma  \\\n",
       "9334                                       NaN   \n",
       "\n",
       "      Bicarbonate [Moles/volume] in Venous blood  \\\n",
       "9334                                         NaN   \n",
       "\n",
       "      Oxygen [Partial pressure] in Arterial blood  \\\n",
       "9334                                          NaN   \n",
       "\n",
       "      Carbon dioxide [Partial pressure] in Arterial blood  \\\n",
       "9334                                                NaN     \n",
       "\n",
       "      Interleukin 6 [Mass/volume] in Body fluid  \\\n",
       "9334                                        NaN   \n",
       "\n",
       "      Magnesium [Moles/volume] in Blood  Prothrombin time (PT)  \\\n",
       "9334                                NaN                    NaN   \n",
       "\n",
       "      Procalcitonin [Mass/volume] in Serum or Plasma  \\\n",
       "9334                                             NaN   \n",
       "\n",
       "      Lactate [Moles/volume] in Blood  Creatinine [Mass/volume] in Blood  \\\n",
       "9334                              NaN                                NaN   \n",
       "\n",
       "      Fibrinogen measurement  Bilirubin measurement  \\\n",
       "9334                     NaN                    NaN   \n",
       "\n",
       "      Partial thromboplastin time   activated  Total white blood count  \\\n",
       "9334                          NaN         NaN                      NaN   \n",
       "\n",
       "      Platelet count  White blood cell count  Blood venous pH  D-dimer level  \\\n",
       "9334             NaN                     NaN              NaN            NaN   \n",
       "\n",
       "      Blood arterial pH  Hemoglobin [Moles/volume] in Blood drugs routes  \\\n",
       "9334                NaN                                 NaN   NaN    NaN   \n",
       "\n",
       "      visit_occurrence_id procedure  person_id  age_in_months gender  \\\n",
       "9334                  NaN       NaN        NaN            NaN    NaN   \n",
       "\n",
       "     birthday_formatted new_visit_startdate  \n",
       "9334                NaT                 NaT  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data_factors_2[data_factors_2['uid']=='nan459121546']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331642"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_factors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_time = list(data_factors_2.loc[data_factors_2['uid'].str.startswith('nan', na=False)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factors_2 = data_factors_2.drop(index = no_time, axis=1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-12-23 16:00:001089329724', '2018-12-24 16:00:001089329724',\n",
       "       '2018-12-25 14:00:001089329724', ..., 'nan459121546',\n",
       "       'nan550654794', 'nan753232477'], dtype=object)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(training_data_2['SepsisLabel_train']['uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[table.startswith(\"measurement_lab\") for table in data_dictionary.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_factors_2.dropna(subset=data_factors_2.select_dtypes(float).columns, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314372"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9334/331642 [00:08<04:41, 1145.36it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnew_person_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_factors_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[160], line 14\u001b[0m, in \u001b[0;36mnew_person_ids\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m     13\u001b[0m     new_id \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m19\u001b[39m:]\n\u001b[1;32m---> 14\u001b[0m     new_person_id\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(new_person_id)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperson_id\u001b[39m\u001b[38;5;124m'\u001b[39m],inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_person_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m new_person_id\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "new_person_ids(data_factors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>uid</th>\n",
       "      <th>Systolic blood pressure</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Body temperature</th>\n",
       "      <th>Respiratory rate</th>\n",
       "      <th>Heart rate</th>\n",
       "      <th>Measurement of oxygen saturation at periphery</th>\n",
       "      <th>Oxygen/Gas total [Pure volume fraction] Inhaled gas</th>\n",
       "      <th>Base excess in Venous blood by calculation</th>\n",
       "      <th>...</th>\n",
       "      <th>drugs</th>\n",
       "      <th>routes</th>\n",
       "      <th>visit_occurrence_id</th>\n",
       "      <th>procedure</th>\n",
       "      <th>person_id</th>\n",
       "      <th>age_in_months</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthday_formatted</th>\n",
       "      <th>new_visit_startdate</th>\n",
       "      <th>new_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31268</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-07 04:00:001678169238</td>\n",
       "      <td>99.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.151260</td>\n",
       "      <td>161.050420</td>\n",
       "      <td>94.101690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-invasive ventilation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>01678169238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216814</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-10 21:00:0017338357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>'dopamine', 'milrinone'</td>\n",
       "      <td>'Intravenous'</td>\n",
       "      <td>1.316976e+09</td>\n",
       "      <td>Non-invasive ventilation</td>\n",
       "      <td>17338357.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>2008-11-10</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>017338357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83131</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-15 16:00:001341079985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>01341079985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70176</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-07 15:00:002005128362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.747826</td>\n",
       "      <td>96.295654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>02005128362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239248</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-13 02:00:00795594587</td>\n",
       "      <td>111.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>48.084034</td>\n",
       "      <td>162.554630</td>\n",
       "      <td>98.151260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0795594587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186244</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-23 17:00:00607345289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cannulation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0607345289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135854</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-11-14 15:00:001430074021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>01430074021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-16 05:00:001332819307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.889830</td>\n",
       "      <td>97.279660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cannulation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>01332819307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89455</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-17 08:00:001048405790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>01048405790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321944</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-03 11:00:001314502207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146.037380</td>\n",
       "      <td>97.859810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exteriorization of trachea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>01314502207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SepsisLabel                            uid  Systolic blood pressure  \\\n",
       "31268             0  2023-11-07 04:00:001678169238                     99.0   \n",
       "216814            0    2020-11-10 21:00:0017338357                      NaN   \n",
       "83131             0  2021-03-15 16:00:001341079985                      NaN   \n",
       "70176             0  2023-12-07 15:00:002005128362                      NaN   \n",
       "239248            0   2024-12-13 02:00:00795594587                    111.0   \n",
       "186244            0   2022-06-23 17:00:00607345289                      NaN   \n",
       "135854            0  2022-11-14 15:00:001430074021                      NaN   \n",
       "4356              0  2024-04-16 05:00:001332819307                      NaN   \n",
       "89455             0  2022-08-17 08:00:001048405790                      NaN   \n",
       "321944            0  2024-02-03 11:00:001314502207                      NaN   \n",
       "\n",
       "        Diastolic blood pressure  Body temperature  Respiratory rate  \\\n",
       "31268                       43.0               NaN         56.151260   \n",
       "216814                       NaN              35.7               NaN   \n",
       "83131                        NaN               NaN               NaN   \n",
       "70176                        NaN               NaN               NaN   \n",
       "239248                      72.0              39.7         48.084034   \n",
       "186244                       NaN              35.5               NaN   \n",
       "135854                       NaN              36.1               NaN   \n",
       "4356                         NaN               NaN               NaN   \n",
       "89455                        NaN               NaN               NaN   \n",
       "321944                       NaN               NaN               NaN   \n",
       "\n",
       "        Heart rate  Measurement of oxygen saturation at periphery  \\\n",
       "31268   161.050420                                      94.101690   \n",
       "216814         NaN                                            NaN   \n",
       "83131          NaN                                            NaN   \n",
       "70176   109.747826                                      96.295654   \n",
       "239248  162.554630                                      98.151260   \n",
       "186244         NaN                                            NaN   \n",
       "135854         NaN                                            NaN   \n",
       "4356     74.889830                                      97.279660   \n",
       "89455          NaN                                            NaN   \n",
       "321944  146.037380                                      97.859810   \n",
       "\n",
       "        Oxygen/Gas total [Pure volume fraction] Inhaled gas  \\\n",
       "31268                                                 NaN     \n",
       "216814                                                NaN     \n",
       "83131                                                 NaN     \n",
       "70176                                                 NaN     \n",
       "239248                                                NaN     \n",
       "186244                                                NaN     \n",
       "135854                                                NaN     \n",
       "4356                                                  NaN     \n",
       "89455                                                 NaN     \n",
       "321944                                                NaN     \n",
       "\n",
       "        Base excess in Venous blood by calculation  ...  \\\n",
       "31268                                          NaN  ...   \n",
       "216814                                         NaN  ...   \n",
       "83131                                          NaN  ...   \n",
       "70176                                          NaN  ...   \n",
       "239248                                         NaN  ...   \n",
       "186244                                         NaN  ...   \n",
       "135854                                         NaN  ...   \n",
       "4356                                           NaN  ...   \n",
       "89455                                          NaN  ...   \n",
       "321944                                         NaN  ...   \n",
       "\n",
       "                          drugs         routes  visit_occurrence_id  \\\n",
       "31268                         a            nan                  NaN   \n",
       "216814  'dopamine', 'milrinone'  'Intravenous'         1.316976e+09   \n",
       "83131                         a            nan                  NaN   \n",
       "70176                         a            nan                  NaN   \n",
       "239248                        a            nan                  NaN   \n",
       "186244                        a            nan                  NaN   \n",
       "135854                        a            nan                  NaN   \n",
       "4356                          a            nan                  NaN   \n",
       "89455                         a            nan                  NaN   \n",
       "321944                        a            nan                  NaN   \n",
       "\n",
       "                         procedure   person_id  age_in_months  gender  \\\n",
       "31268     Non-invasive ventilation         NaN            NaN     NaN   \n",
       "216814    Non-invasive ventilation  17338357.0          144.0  FEMALE   \n",
       "83131                          NaN         NaN            NaN     NaN   \n",
       "70176                          NaN         NaN            NaN     NaN   \n",
       "239248                         NaN         NaN            NaN     NaN   \n",
       "186244                 Cannulation         NaN            NaN     NaN   \n",
       "135854                         NaN         NaN            NaN     NaN   \n",
       "4356                   Cannulation         NaN            NaN     NaN   \n",
       "89455                          NaN         NaN            NaN     NaN   \n",
       "321944  Exteriorization of trachea         NaN            NaN     NaN   \n",
       "\n",
       "        birthday_formatted  new_visit_startdate  new_person_id  \n",
       "31268                  NaT                  NaT    01678169238  \n",
       "216814          2008-11-10           2020-11-09      017338357  \n",
       "83131                  NaT                  NaT    01341079985  \n",
       "70176                  NaT                  NaT    02005128362  \n",
       "239248                 NaT                  NaT     0795594587  \n",
       "186244                 NaT                  NaT     0607345289  \n",
       "135854                 NaT                  NaT    01430074021  \n",
       "4356                   NaT                  NaT    01332819307  \n",
       "89455                  NaT                  NaT    01048405790  \n",
       "321944                 NaT                  NaT    01314502207  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_factors_2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_encoding(df):\n",
    "    categorical_cols = list(df.select_dtypes(object).columns)\n",
    "    le_dictionary = {}\n",
    "    for name in tqdm(categorical_cols):\n",
    "        print(name)\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df.loc[:,f'{name}'])\n",
    "        new_col = le.transform(df.loc[:,f'{name}'])\n",
    "        le_dictionary[name] = le\n",
    "        df.drop(columns=f'{name}', inplace=True)\n",
    "        df[f'new_{name}'] = new_col\n",
    "        print(f'finished {name}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_modeling(df):\n",
    "    column_list = []\n",
    "    [column_list.append(i) for i in range(3,46)]\n",
    "    X = df.iloc[:,column_list].values\n",
    "    y = df.iloc[:,1].values\n",
    "    person_id = df.iloc[:,0].values\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2)\n",
    "    for train_x_index, test_x_index in gss.split(X=X,y=y,groups=person_id):\n",
    "        X_train = X[train_x_index]\n",
    "        X_test = X[test_x_index]\n",
    "        y_train = y[train_x_index]\n",
    "        y_test = y[test_x_index]\n",
    "        person_id_train = person_id[train_x_index]\n",
    "        person_id_test = person_id[test_x_index]\n",
    "        \n",
    "    formatted_data = {}\n",
    "    formatted_data['X_train'] = X_train\n",
    "    formatted_data['X_test'] = X_test\n",
    "    formatted_data['y_train'] = y_train\n",
    "    formatted_data['y_test'] = y_test\n",
    "    formatted_data['person_id_train'] = person_id_train\n",
    "    formatted_data['person_id_test'] = person_id_test\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_model(data_dictionary: dict):\n",
    "    X_train = data_dictionary['X_train']\n",
    "    X_test = data_dictionary['X_test']\n",
    "    y_train = data_dictionary['y_train']\n",
    "    y_test = data_dictionary['y_test']\n",
    "    person_id_train = data_dictionary['person_id_train']\n",
    "    person_id_test = data_dictionary['person_id_test']\n",
    "\n",
    "    r_forest_model = RandomForestClassifier()\n",
    "    r_forest_model.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = forest_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy score: {accuracy}\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=['not sepsis', 'sepsis'], yticklabels=['not sepsis', 'sepsis'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show(block=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
