{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV \n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readin_data(data_type: str):\n",
    "    \"\"\" This function reads in test or train data, which must be in folders 'testing_data' and 'training_data' in the same directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_type' : str\n",
    "        This must be 'test' or 'train'.\n",
    "    \"\"\"\n",
    "    assert (data_type=='test') or (data_type=='train'), f'You gave data_type as {data_type}. Please define data_type as \"test\" or \"train.\"'\n",
    "    if data_type == 'test':\n",
    "        inner_directory = './testing_data/'\n",
    "        data_list = os.listdir('./testing_data')\n",
    "    else:\n",
    "        inner_directory = './training_data/'\n",
    "        data_list = os.listdir('./training_data')\n",
    "    data_dict = {}\n",
    "    for file_name in data_list:\n",
    "        data_dict[file_name.split('.')[0]] = pd.read_csv(inner_directory+file_name).drop_duplicates()\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_data_directory():\n",
    "    \"\"\" Makes 'processed_data' directory if one is not found.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Add flag for this function\n",
    "    os.makedirs('./processed_data', exist_ok=True)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_uids(data_dictionary: dict):\n",
    "    \"\"\" This function adds a UID to each row to establish unique instances between person_id & measurement datetimes for the various tables.\n",
    "    \n",
    "    This is not done for the demographics file since the information in it is not sensitive to the hour.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \n",
    "    Details\n",
    "    -------\n",
    "    * UID is a concatenation of datetime and person_id, in that order.\n",
    "    * UID is later used as a key for table joins.\n",
    "    \"\"\"\n",
    "    print(\"Adding UIDs.\")\n",
    "\n",
    "    for table_ind in list(data_dictionary.keys()):\n",
    "        if not table_ind.startswith(\"person_demographics\"):\n",
    "            table = data_dictionary[table_ind]\n",
    "            datetime_index = np.argmax([i.find('datetime') for i in table.columns])\n",
    "            date_column = table.columns[datetime_index]\n",
    "            personid_index = np.argmax([i.find('person_id') for i in table.columns])\n",
    "            personid_column = table.columns[personid_index]\n",
    "            table['uid'] = table[date_column].astype(str) + table[personid_column].astype(str)\n",
    "            table.drop(columns=[date_column,personid_column],inplace=True)\n",
    "            data_dictionary[table_ind] = table\n",
    "            # print(f'file {table_ind} with len {len(table)}')\n",
    "    \n",
    "    print(\"UIDs added\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birthday_management(data_dictionary: dict):\n",
    "    \"\"\"\n",
    "    This function processes the 'person_demographics' table of given data, which is inputed as a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \n",
    "    Details\n",
    "    -------\n",
    "    * adds new birthday and visit start date columns with dates formated using datetime package.\n",
    "    * joins new columns to old table using left join to match the unprocessed to the processed date\n",
    "    \"\"\"\n",
    "    demographics_ind_no = np.argmax([table.startswith(\"person_demographics\") for table in data_dictionary.keys()])\n",
    "    demographics_index = list(data_dictionary.keys())[demographics_ind_no]\n",
    "    demographics = data_dictionary[demographics_index]\n",
    "    print(f\"Beginning processing for {demographics_index}.\")\n",
    "    \n",
    "\n",
    "    new_birthday_col = pd.DataFrame(columns=['birthday_formatted', 'person_id'])\n",
    "    new_visit_col = pd.DataFrame(columns=['visit_start_date','new_visit_startdate'])\n",
    "    \n",
    "    for person in np.unique(demographics['person_id']):\n",
    "        birthday = demographics[demographics['person_id']==person]['birth_datetime'].to_list()[0]\n",
    "        birthday_formatted = datetime.strptime(birthday,'%Y-%m-%d')\n",
    "        new_birthday_col.loc[len(new_birthday_col)] = [birthday_formatted, person]\n",
    "\n",
    "    for date in np.unique(demographics['visit_start_date']):\n",
    "        visit_start = demographics[demographics['visit_start_date']==date]['visit_start_date'].to_list()[0]\n",
    "        new_visit_startdate = datetime.strptime(visit_start,'%Y-%m-%d')\n",
    "        # print(f'new {new_visit_startdate} old {date}')\n",
    "        new_visit_col.loc[len(new_visit_col)] = [date, new_visit_startdate]\n",
    "\n",
    "\n",
    "    demographics = pd.merge(left=demographics,right=new_birthday_col,how='left',on='person_id')\n",
    "    demographics = pd.merge(left=demographics,right=new_visit_col,how='left',on='visit_start_date')\n",
    "    demographics.drop(columns=['visit_start_date','birth_datetime'],inplace=True)\n",
    "    demographics.to_csv(f'./processed_data/processed_{demographics_index}.csv')\n",
    "    data_dictionary[demographics_index] = demographics\n",
    "    print(f\"Finished processing of {demographics_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_meds_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'measurement_meds' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "\n",
    "    Details\n",
    "    -------\n",
    "    * removes body temperature measurements > 46 C\n",
    "    \"\"\"\n",
    "    body_measurements_ind = np.argmax([table.startswith(\"measurement_meds\") for table in data_dictionary.keys()])\n",
    "    body_measurements_index = list(data_dictionary.keys())[body_measurements_ind]\n",
    "    measurements = data_dictionary[body_measurements_index]\n",
    "    print(f\"Beginning processing for {body_measurements_index}.\")\n",
    "\n",
    "    \n",
    "    measurements = measurements.dropna(subset=measurements.select_dtypes(float).columns, how='all')\n",
    "    # measurements.drop(index=[i for i in measurements[measurements['Body temperature']>45].index], axis=1,inplace=True)\n",
    "    measurements['Body temperature'] = measurements['Body temperature'].apply(lambda x: np.nan if x > 46 else x)\n",
    "    measurements.to_csv(f'./processed_data/processed_{body_measurements_index}.csv')\n",
    "    data_dictionary[body_measurements_index] = measurements\n",
    "    print(f\"Finished processing of {body_measurements_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drugs_exposure_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'drugsexposure' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    You need to run add_uids first.\n",
    "\n",
    "    Details\n",
    "    -------\n",
    "    * combines rows of the same datetime with different drugs to be one row per datetime with all drugs listed in new 'drugs' column and all drug routes listed in new 'routes' column\n",
    "    * converts from list to string for new columns to allow categorical encoding later on\n",
    "    \"\"\"\n",
    "    # assert uids_added == True, 'You need to run add_uids before this function.'\n",
    "    drugs_exposure_ind = np.argmax([table.startswith(\"drugsexposure\") for table in data_dictionary.keys()])\n",
    "    drugs_exposure_index = list(data_dictionary.keys())[drugs_exposure_ind]\n",
    "    drugs_exposure = data_dictionary[drugs_exposure_index]\n",
    "    print(f\"Beginning processing for {drugs_exposure_index}.\")\n",
    "\n",
    "    drugs_exposure_processed = pd.DataFrame(columns = ['uid', 'drugs', 'routes', 'visit_occurrence_id'])\n",
    "    \n",
    "    for x in tqdm(np.unique(drugs_exposure['uid'])):\n",
    "        drugs = drugs_exposure[drugs_exposure['uid']==x]['drug_concept_id'].to_list()\n",
    "        drugs.sort()\n",
    "        try:\n",
    "            route = drugs_exposure[drugs_exposure['uid']==x]['route_concept_id'].to_list()\n",
    "            route = list(set(route))\n",
    "            route = [str(i) for i in route]\n",
    "            route.sort()\n",
    "        except:\n",
    "            route = drugs_exposure[drugs_exposure['uid']==x]['route_concept_id'].to_list()\n",
    "            route = list(set(route))\n",
    "        visit_occurrence = drugs_exposure[drugs_exposure['uid']==x]['visit_occurrence_id'].to_list()[0]\n",
    "        drugs_exposure_processed.loc[len(drugs_exposure_processed)]= [x,drugs,route, visit_occurrence]\n",
    "    # switching format from list to string for later processing of categorical data:\n",
    "    for row in drugs_exposure_processed['drugs']:\n",
    "        row = str(row)[1:-1]\n",
    "    for row in drugs_exposure_processed['routes']:\n",
    "        row = str(row)[1:-1]\n",
    "\n",
    "    drugs_exposure_processed['drugs'] = drugs_exposure_processed['drugs'].apply(lambda x: str(x)[1:-1])\n",
    "    drugs_exposure_processed['drugs'] = drugs_exposure_processed['drugs'].apply(lambda x: np.nan if x=='a' else x)\n",
    "\n",
    "\n",
    "    drugs_exposure_processed['routes'] = drugs_exposure_processed['routes'].apply(lambda x: np.nan if x is str else str(x)[1:-1])\n",
    "    drugs_exposure_processed['routes'] = drugs_exposure_processed['routes'].apply(lambda x: np.nan if x=='a' else x)\n",
    "\n",
    "    data_dictionary[drugs_exposure_index] = drugs_exposure_processed\n",
    "\n",
    "\n",
    "    drugs_exposure.to_csv(f'./processed_data/processed_{drugs_exposure_index}.csv')\n",
    "    print(f\"Finished processing of {drugs_exposure_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_lab_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'measurement_lab' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    You need to run add_uids first.\n",
    "\n",
    "    Details\n",
    "    -------\n",
    "    * removes rows which are all NA\n",
    "    * combines rows which have the same datetime but different columns filled (different columns have non-NA values)\n",
    "    * converts columns to float to resolve typing issue\n",
    "    \"\"\"\n",
    "    # assert uids_added == True, 'You need to run add_uids before this function.'\n",
    "\n",
    "    measurement_lab_ind = np.argmax([table.startswith(\"measurement_lab\") for table in data_dictionary.keys()])\n",
    "    measurement_lab_index = list(data_dictionary.keys())[measurement_lab_ind]\n",
    "    measurement_lab = data_dictionary[measurement_lab_index]\n",
    "    print(f\"Beginning processing for {measurement_lab_index}.\")\n",
    "\n",
    "    nan_col_inds = list(measurement_lab.isna().all())\n",
    "    nan_col_indices = list(measurement_lab.loc[:,nan_col_inds].columns)\n",
    "    measurement_lab.drop(columns=nan_col_indices, inplace=True)\n",
    "\n",
    "    measurement_lab = measurement_lab.dropna(subset=list(measurement_lab.select_dtypes(float).columns), how='all')\n",
    "    measurement_lab_count = pd.DataFrame([list(i) for i in Counter(measurement_lab['uid']).items()],columns=['uid','count'])\n",
    "    measurement_lab_count['count'].astype(int)\n",
    "    measurement_lab_rows = pd.DataFrame()\n",
    "    measurement_lab_extras = measurement_lab_count[measurement_lab_count['count']>1]\n",
    "    for j in [i for i in measurement_lab_extras['uid']]:\n",
    "        measurement_lab_rows = pd.concat([measurement_lab_rows,measurement_lab[measurement_lab['uid']==j].max().to_frame().T]).reset_index(drop=True)\n",
    "    measurement_lab = measurement_lab.drop(index=[i for i in measurement_lab[measurement_lab['uid']==measurement_lab_extras['uid'].item()].index], axis=1,inplace=False)\n",
    "    measurement_lab = pd.concat([measurement_lab,measurement_lab_rows]).reset_index(drop=True)\n",
    "\n",
    "    col_inds = [not((i.endswith('_id')) or (i=='uid')) for i in list(measurement_lab.columns)]\n",
    "    col_names = measurement_lab.columns.values[col_inds]\n",
    "    for column in col_names:\n",
    "        measurement_lab[column] = measurement_lab[column].astype(float)\n",
    "\n",
    "    measurement_lab.to_csv(f'./processed_data/processed_{measurement_lab_index}.csv')\n",
    "    data_dictionary[measurement_lab_index] = measurement_lab\n",
    "    print(f\"Finished processing of {measurement_lab_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_observation_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'measurement_observation' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \n",
    "    Details\n",
    "    -------\n",
    "    * creates csv to verify this table has been processed.\n",
    "    \"\"\"\n",
    "\n",
    "    measurement_obs_ind = np.argmax([table.startswith(\"measurement_observation\") for table in data_dictionary.keys()])\n",
    "    measurement_obs_index = list(data_dictionary.keys())[measurement_obs_ind]\n",
    "    measurement_obs = data_dictionary[measurement_obs_index]\n",
    "    print(f\"Beginning processing for {measurement_obs_index}.\")\n",
    "\n",
    "    # measurement_obs = measurement_obs.dropna(subset=measurement_obs.select_dtypes(float).columns, how='all')\n",
    "    measurement_obs.to_csv(f'./processed_data/processed_{measurement_obs_index}.csv')\n",
    "    data_dictionary[measurement_obs_index] = measurement_obs\n",
    "    print(f\"Finished processing of {measurement_obs_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'observation' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \n",
    "    Details\n",
    "    -------\n",
    "    * creates csv to verify this table has been processed.\n",
    "    \"\"\"\n",
    "\n",
    "    observation_ind = np.argmax([table.startswith(\"observation\") for table in data_dictionary.keys()])\n",
    "    observation_index = list(data_dictionary.keys())[observation_ind]\n",
    "    observation = data_dictionary[observation_index]\n",
    "    print(f\"Beginning processing for {observation_index}.\")\n",
    "\n",
    "\n",
    "    observation = observation.dropna(subset=observation.select_dtypes(object).columns, how='all')\n",
    "\n",
    "    observation.to_csv(f'./processed_data/processed_{observation_index}.csv')\n",
    "\n",
    "    data_dictionary[observation_index] = observation \n",
    "    print(f\"Finished processing of {observation_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedures_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'observation' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    You need to run add_uids first.\n",
    "    \n",
    "    Details\n",
    "    -------\n",
    "    * drops visit_occurrence column\n",
    "    * drops duplicate entries\n",
    "    \"\"\"\n",
    "    # assert uids_added == True, 'You need to run add_uids before this function.'\n",
    "\n",
    "    procedures_ind = np.argmax([table.startswith(\"proceduresoccurrences\") for table in data_dictionary.keys()])\n",
    "    procedures_index = list(data_dictionary.keys())[procedures_ind]\n",
    "    procedures = data_dictionary[procedures_index]\n",
    "    print(f\"Beginning processing for {procedures_index}.\")\n",
    "\n",
    "    procedures = procedures.dropna(subset=procedures.select_dtypes(object).columns, how='all')\n",
    "\n",
    "\n",
    "    visit_id_index = np.argmax([i.find('visit_occurrence') for i in procedures.columns])\n",
    "    visit_column = procedures.columns[visit_id_index]\n",
    "    procedures.drop(columns=visit_column,inplace=True)\n",
    "    procedures.drop_duplicates(inplace=True)\n",
    "\n",
    "    procedures.to_csv(f'./processed_data/processed_{procedures_index}.csv')\n",
    "\n",
    "\n",
    "    data_dictionary[procedures_index] = procedures \n",
    "    print(f\"Finished processing of {procedures_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devices_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'devices' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \n",
    "    Details\n",
    "    -------\n",
    "    * creates csv to verify this table has been processed.\n",
    "    \"\"\"\n",
    "\n",
    "    devices_ind = np.argmax([table.startswith(\"devices\") for table in data_dictionary.keys()])\n",
    "    devices_index = list(data_dictionary.keys())[devices_ind]\n",
    "    devices = data_dictionary[devices_index]\n",
    "    print(f\"Beginning processing for {devices_index}.\")\n",
    "\n",
    "    devices = devices.dropna(subset=devices.select_dtypes(object).columns, how='all')\n",
    "\n",
    "    devices.to_csv(f'./processed_data/processed_{devices_index}.csv')\n",
    "\n",
    "    data_dictionary[devices_index] = devices\n",
    "    print(f\"Finished processing of {devices_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepsis_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'sepsis' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \n",
    "    Details\n",
    "    -------\n",
    "    * drops values which have no datetime\n",
    "    \"\"\"\n",
    "    sepsis_ind = np.argmax([table.startswith(\"SepsisLabel\") for table in data_dictionary.keys()])\n",
    "    sepsis_index = list(data_dictionary.keys())[sepsis_ind]\n",
    "    sepsis = data_dictionary[sepsis_index]\n",
    "    print(f\"Beginning processing for {sepsis_index}.\")\n",
    "\n",
    "    #no NA values found:\n",
    "    sepsis = sepsis.dropna(subset=sepsis.select_dtypes(int).columns, how='all')\n",
    "    #Taking out values that have no datetime:\n",
    "    no_time_rows = list(sepsis.loc[sepsis['uid'].str.startswith('nan', na=False)].index)\n",
    "    print(no_time_rows)\n",
    "    sepsis = sepsis.drop(index=no_time_rows, axis = 1, inplace = False)\n",
    "    \n",
    "    data_dictionary[sepsis_index] = sepsis\n",
    "    \n",
    "    print(f\"Finished processing of {sepsis_index}.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_type: str, load_tables: str):\n",
    "    \"\"\" This function reads in test or train data and goes through functions to preprocess it. For further details see specific functions.\n",
    "\n",
    "    Processed tables will be saved into the /processed folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_type' : str\n",
    "        This must be 'test' or 'train'. Determines which data to process.\n",
    "    'load_tables' : str\n",
    "        This must be 'yes' or 'no'. 'yes' means load csvs from processed_data folder, of the type given in 'data_type' input. 'no' means process data from training or testing folder, depending on 'data_type' input given.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    'processed_data' : dict\n",
    "        This is a dictionary of datatables that have been processed\n",
    "    'factors' : DataFrame\n",
    "        This is a DataFrame of the data from 'processed_data' joined together.\n",
    "    \"\"\"\n",
    "    assert (data_type=='test') or (data_type=='train'), f'You gave data_type as {data_type}. Please define data_type as \"test\" or \"train.\"'\n",
    "    assert (load_tables=='yes') or (load_tables=='no'), f'You gave load_tables as {load_tables}. Please define load_tables as \"test\" or \"train.\"'\n",
    "\n",
    "    processed_data_directory()\n",
    "\n",
    "    if data_type == 'train':\n",
    "        if load_tables == 'no':\n",
    "            training_data = readin_data('train')\n",
    "            add_uids(training_data)\n",
    "            birthday_management(training_data)\n",
    "            measurement_meds_processing(training_data)\n",
    "            drugs_exposure_processing(training_data)\n",
    "            measurement_lab_processing(training_data)\n",
    "            procedures_processing(training_data)\n",
    "            observation_processing(training_data)\n",
    "            measurement_observation_processing(training_data)\n",
    "            devices_processing(training_data)\n",
    "            sepsis_processing(training_data)\n",
    "        else:\n",
    "            training_data={}\n",
    "            inner_directory = './processed_data/'\n",
    "            data_list = os.listdir('./processed_data')\n",
    "            separator = '_'\n",
    "            for file_name in data_list:\n",
    "                if file_name.split('.')[0].split('_')[-1]=='train':\n",
    "                    training_data[separator.join(file_name.split('.')[0].split('_')[1:])] = pd.read_csv(inner_directory+file_name,index_col=0).drop_duplicates()\n",
    "\n",
    "        factors = pd.merge(left=training_data['measurement_meds_train'], right=training_data['measurement_lab_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['drugsexposure_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['proceduresoccurrences_train'],how='outer',on='uid')\n",
    "        # factors = pd.merge(left=factors, right=training_data['person_demographics_episode_train'], how='outer',on='visit_occurrence_id')\n",
    "        factors = pd.merge(left=training_data['SepsisLabel_train'],right=factors,how='left',on='uid')\n",
    "        factors.to_csv(f'./processed_data/factors_train.csv')\n",
    "        processed_data = training_data\n",
    "\n",
    "    else:\n",
    "        if load_tables == 'no':\n",
    "            testing_data = readin_data('test')\n",
    "            add_uids(testing_data)\n",
    "            birthday_management(testing_data)\n",
    "            measurement_meds_processing(testing_data)\n",
    "            drugs_exposure_processing(testing_data)\n",
    "            measurement_lab_processing(testing_data)\n",
    "            procedures_processing(testing_data)\n",
    "            observation_processing(testing_data)\n",
    "            measurement_observation_processing(testing_data)\n",
    "            devices_processing(testing_data)\n",
    "            sepsis_processing(testing_data)\n",
    "        else:\n",
    "            training_data={}\n",
    "            inner_directory = './processed_data/'\n",
    "            data_list = os.listdir('./processed_data')\n",
    "            separator = '_'\n",
    "            for file_name in data_list:\n",
    "                if file_name.split('.')[0].split('_')[-1]=='test':\n",
    "                    training_data[separator.join(file_name.split('.')[0].split('_')[1:])] = pd.read_csv(inner_directory+file_name,index_col=0).drop_duplicates()\n",
    "            \n",
    "        factors = pd.merge(left=testing_data['measurement_meds_test'], right=testing_data['measurement_lab_test'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=testing_data['drugsexposure_test'],how='outer',on='uid')\n",
    "        # factors = pd.merge(left=factors, right=testing_data['person_demographics_episode_test'], how='outer',on='visit_occurrence_id')\n",
    "        factors = pd.merge(left=testing_data['SepsisLabel_test'],right=factors,how='left',on='uid')\n",
    "        factors.to_csv(f'./processed_data/factors_test.csv')\n",
    "        processed_data = testing_data\n",
    "\n",
    "    factors.drop(columns=['visit_occurrence_id_x','visit_occurrence_id_y'],inplace=True)\n",
    "\n",
    "    return processed_data, factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_directory = './processed_data/'\n",
    "data_list = os.listdir('./processed_data')\n",
    "\n",
    "data_dict = {}\n",
    "separator = '_'\n",
    "for file_name in data_list:\n",
    "    if file_name.split('.')[0].split('_')[-1]=='train':\n",
    "        data_dict[separator.join(file_name.split('.')[0].split('_')[1:])] = pd.read_csv(inner_directory+file_name,index_col=0).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'drugsexposure_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_data, trained_factors \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 48\u001b[0m, in \u001b[0;36mprocess_data\u001b[1;34m(data_type, load_tables)\u001b[0m\n\u001b[0;32m     45\u001b[0m             training_data[separator\u001b[38;5;241m.\u001b[39mjoin(file_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m:])] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(inner_directory\u001b[38;5;241m+\u001b[39mfile_name,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m     47\u001b[0m factors \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(left\u001b[38;5;241m=\u001b[39mtraining_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeasurement_meds_train\u001b[39m\u001b[38;5;124m'\u001b[39m], right\u001b[38;5;241m=\u001b[39mtraining_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeasurement_lab_train\u001b[39m\u001b[38;5;124m'\u001b[39m],how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m,on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m factors \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(left\u001b[38;5;241m=\u001b[39mfactors, right\u001b[38;5;241m=\u001b[39m\u001b[43mtraining_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrugsexposure_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m,on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m factors \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(left\u001b[38;5;241m=\u001b[39mfactors, right\u001b[38;5;241m=\u001b[39mtraining_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproceduresoccurrences_train\u001b[39m\u001b[38;5;124m'\u001b[39m],how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m,on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# factors = pd.merge(left=factors, right=training_data['person_demographics_episode_train'], how='outer',on='visit_occurrence_id')\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'drugsexposure_train'"
     ]
    }
   ],
   "source": [
    "trained_data, trained_factors = process_data(data_type='train', load_tables='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding UIDs.\n",
      "UIDs added\n",
      "Beginning processing for person_demographics_episode_train.\n",
      "Finished processing of person_demographics_episode_train.\n",
      "Beginning processing for measurement_meds_train.\n",
      "Finished processing of measurement_meds_train.\n",
      "Beginning processing for drugsexposure_train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150407/150407 [2:20:45<00:00, 17.81it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing of drugsexposure_train.\n",
      "Beginning processing for measurement_lab_train.\n",
      "Finished processing of measurement_lab_train.\n",
      "Beginning processing for proceduresoccurrences_train.\n",
      "Finished processing of proceduresoccurrences_train.\n",
      "Beginning processing for observation_train.\n",
      "Finished processing of observation_train.\n",
      "Beginning processing for measurement_observation_train.\n",
      "Finished processing of measurement_observation_train.\n",
      "Beginning processing for devices_train.\n",
      "Finished processing of devices_train.\n",
      "Beginning processing for SepsisLabel_train.\n",
      "[9334, 31978, 49555, 101232, 103612, 132662, 136028, 137412, 138129, 176938, 191287, 236491, 241192, 242348, 250585]\n",
      "Finished processing of SepsisLabel_train.\n"
     ]
    }
   ],
   "source": [
    "training_data, data_factors = process_data(data_type='train', load_tables='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(data_directory: dict, data_type: str):\n",
    "    \"\"\" This function takes a data dictionary of tables and merges to have a table of factors for categorical encoding etc.\n",
    "\n",
    "    \n",
    "    note that this function is currently untested.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_directory' : dict\n",
    "        This is a data dictionary of pandas DataFrames.\n",
    "    'data_type' : str\n",
    "        This must be 'test' or 'train'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    'factors' : DataFrame\n",
    "        This is a DataFrame of the data from 'processed_data' joined together.    \n",
    "    \"\"\"\n",
    "    assert (data_type=='test') or (data_type=='train'), f'You gave data_type as {data_type}. Please define data_type as \"test\" or \"train.\"'\n",
    "\n",
    "    if data_type == 'train':\n",
    "        training_data = data_directory.copy()\n",
    "\n",
    "        factors = pd.merge(left=training_data['measurement_meds_train'], right=training_data['measurement_lab_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['drugsexposure_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['proceduresoccurrences_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['person_demographics_episode_train'], how='outer',on='visit_occurrence_id')\n",
    "        factors = pd.merge(left=training_data['SepsisLabel_train'],right=factors,how='left',on='uid')\n",
    "\n",
    "    else:\n",
    "        testing_data = data_directory.copy()\n",
    "\n",
    "        factors = pd.merge(left=testing_data['measurement_meds_test'], right=testing_data['measurement_lab_test'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=testing_data['drugsexposure_test'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=testing_data['person_demographics_episode_test'], how='outer',on='visit_occurrence_id')\n",
    "        factors = pd.merge(left=testing_data['SepsisLabel_test'],right=factors,how='left',on='uid')\n",
    "\n",
    "    factors.to_csv(f'./processed_data/processed_{factors}.csv')\n",
    "\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factors_2 = data_factors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 331627 entries, 0 to 331626\n",
      "Data columns (total 54 columns):\n",
      " #   Column                                               Non-Null Count   Dtype         \n",
      "---  ------                                               --------------   -----         \n",
      " 0   SepsisLabel                                          331627 non-null  int64         \n",
      " 1   uid                                                  331627 non-null  object        \n",
      " 2   Systolic blood pressure                              38380 non-null   float64       \n",
      " 3   Diastolic blood pressure                             38367 non-null   float64       \n",
      " 4   Body temperature                                     198709 non-null  float64       \n",
      " 5   Respiratory rate                                     79352 non-null   float64       \n",
      " 6   Heart rate                                           92769 non-null   float64       \n",
      " 7   Measurement of oxygen saturation at periphery        92613 non-null   float64       \n",
      " 8   Oxygen/Gas total [Pure volume fraction] Inhaled gas  2043 non-null    float64       \n",
      " 9   Base excess in Venous blood by calculation           19054 non-null   float64       \n",
      " 10  Base excess in Arterial blood by calculation         2413 non-null    float64       \n",
      " 11  Phosphate [Moles/volume] in Serum or Plasma          10056 non-null   float64       \n",
      " 12  Potassium [Moles/volume] in Blood                    31660 non-null   float64       \n",
      " 13  Bilirubin.total [Moles/volume] in Serum or Plasma    14595 non-null   float64       \n",
      " 14  Neutrophil Ab [Units/volume] in Serum                24638 non-null   float64       \n",
      " 15  Bicarbonate [Moles/volume] in Arterial blood         2413 non-null    float64       \n",
      " 16  Hematocrit [Volume Fraction] of Blood                27697 non-null   float64       \n",
      " 17  Glucose [Moles/volume] in Serum or Plasma            16326 non-null   float64       \n",
      " 18  Calcium [Moles/volume] in Serum or Plasma            8349 non-null    float64       \n",
      " 19  Chloride [Moles/volume] in Blood                     32508 non-null   float64       \n",
      " 20  Sodium [Moles/volume] in Serum or Plasma             32456 non-null   float64       \n",
      " 21  C reactive protein [Mass/volume] in Serum or Plasma  22914 non-null   float64       \n",
      " 22  Carbon dioxide [Partial pressure] in Venous blood    19056 non-null   float64       \n",
      " 23  Oxygen [Partial pressure] in Venous blood            21382 non-null   float64       \n",
      " 24  Albumin [Mass/volume] in Serum or Plasma             12580 non-null   float64       \n",
      " 25  Bicarbonate [Moles/volume] in Venous blood           21417 non-null   float64       \n",
      " 26  Oxygen [Partial pressure] in Arterial blood          2412 non-null    float64       \n",
      " 27  Carbon dioxide [Partial pressure] in Arterial blood  2413 non-null    float64       \n",
      " 28  Interleukin 6 [Mass/volume] in Body fluid            60 non-null      float64       \n",
      " 29  Magnesium [Moles/volume] in Blood                    11477 non-null   float64       \n",
      " 30  Prothrombin time (PT)                                7808 non-null    float64       \n",
      " 31  Procalcitonin [Mass/volume] in Serum or Plasma       12580 non-null   float64       \n",
      " 32  Lactate [Moles/volume] in Blood                      19827 non-null   float64       \n",
      " 33  Creatinine [Mass/volume] in Blood                    25850 non-null   float64       \n",
      " 34  Fibrinogen measurement                               7756 non-null    float64       \n",
      " 35  Bilirubin measurement                                11401 non-null   float64       \n",
      " 36  Partial thromboplastin time                          7757 non-null    float64       \n",
      " 37   activated                                           24786 non-null   float64       \n",
      " 38  Total white blood count                              24728 non-null   float64       \n",
      " 39  Platelet count                                       6360 non-null    float64       \n",
      " 40  White blood cell count                               21635 non-null   float64       \n",
      " 41  Blood venous pH                                      367 non-null     float64       \n",
      " 42  D-dimer level                                        2415 non-null    float64       \n",
      " 43  Blood arterial pH                                    27082 non-null   float64       \n",
      " 44  Hemoglobin [Moles/volume] in Blood                   24590 non-null   float64       \n",
      " 45  drugs                                                66443 non-null   object        \n",
      " 46  routes                                               66443 non-null   object        \n",
      " 47  visit_occurrence_id                                  66443 non-null   float64       \n",
      " 48  procedure                                            195517 non-null  object        \n",
      " 49  person_id                                            66443 non-null   float64       \n",
      " 50  age_in_months                                        66443 non-null   float64       \n",
      " 51  gender                                               66443 non-null   object        \n",
      " 52  birthday_formatted                                   66443 non-null   datetime64[ns]\n",
      " 53  new_visit_startdate                                  66443 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(46), int64(1), object(5)\n",
      "memory usage: 136.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_factors_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_2 = training_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'drugs', 'routes', 'procedure', 'gender'], dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_factors_2.select_dtypes(object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_person_ids(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    This function reads person_id column for all rows based on UID and adds a new column with this information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'df': pandas DataFrame\n",
    "        This should be a pandas DataFrame which contains a column 'uid' with universal ids, with strings with format s.t. the person_id starts at the 18th index. e.g.: '2021-07-21 12:00:00623183219'\n",
    "    \"\"\"\n",
    "    # assert that uid column exists\n",
    "    print('Beginning adding new_person_id column based on uids.')\n",
    "    new_person_ids = pd.DataFrame(columns=['new_person_id','uid'])\n",
    "    new_id = df['uid'].copy().apply(lambda x: x[19:])\n",
    "    # new_id.apply(lambda x: int(x))\n",
    "    new_id = new_id.astype(int)\n",
    "    new_person_ids['new_person_id'] = new_id\n",
    "    new_person_ids['uid'] = df['uid'].copy()\n",
    "    # df.drop(columns=['person_id'],inplace=True)\n",
    "    df['new_person_id']=new_person_ids['new_person_id']\n",
    "    print('Finished adding new_person_id column based on uids.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning adding new_person_id column based on uids.\n",
      "Finished adding new_person_id column based on uids.\n"
     ]
    }
   ],
   "source": [
    "new_person_ids(data_factors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birthday_ubiquity(df: pd.DataFrame, data_dictionary: dict):\n",
    "    \"\"\"\n",
    "    This function adds age in months to all rows in df based on uid time and birthday. It also adds gender to all rows in df.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'df': pandas DataFrame\n",
    "        This is a pandas DataFrame of patient data that contains a 'new_person_id' column from running new_person_ids function.\n",
    "    'data_dictionary': dictionary\n",
    "        This is a dictionary of pandas DataFrames, should have a table of 'person_demographics_episode' data. The 'person_demographics_episode' data will be used to establish birthdays and genders for patients who occur in the DataFrame given.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    'df': pandas DataFrame\n",
    "        returns df with age in months and gender for participants with entry in 'person_demographics_episode' from provided data_dictionary.\n",
    "\n",
    "    Details\n",
    "    -------\n",
    "    * makes temporary dataframe 'unique_demographics_rows' of gender and birthday from 'person_demographics_episode'\n",
    "    * temporarily adds birthday by joining birthday from 'unique_demographics_rows' to df with key as new_person_id\n",
    "    * temporarily creates datetime column derived from uid\n",
    "    * adds age in months column by time between uid date and birthday to df in new column\n",
    "    * deletes birthday column from df\n",
    "    * adds gender column by joining gender from 'unique_demographics_rows' to df with key as new_person_id\n",
    "    \"\"\"\n",
    "    #assert that new_person_id column exists\n",
    "\n",
    "    # factors = pd.merge(left=testing_data['SepsisLabel_test'],right=factors,how='left',on='uid')\n",
    "\n",
    "\n",
    "    demographics_ind_no = np.argmax([table.startswith(\"person_demographics\") for table in data_dictionary.keys()])\n",
    "    demographics_index = list(data_dictionary.keys())[demographics_ind_no]\n",
    "    demographics = data_dictionary[demographics_index]\n",
    "\n",
    "    unique_demographics_rows = pd.DataFrame(columns=['new_person_id','gender','birthday'])\n",
    "    for patient in np.unique(demographics['person_id']):\n",
    "        birthday = list(demographics[demographics['person_id']==patient]['birthday_formatted'])[0]\n",
    "        gender = list(demographics[demographics['person_id']==patient]['gender'])[0]\n",
    "        unique_demographics_rows.loc[len(unique_demographics_rows)] = [patient, gender, birthday]\n",
    "    df = pd.merge(left=df, right=unique_demographics_rows, how='left', on='new_person_id')\n",
    "    datetime_temp = df['uid'].copy().apply(lambda x: x[:19])\n",
    "    datetime_temp = pd.to_datetime(datetime_temp)\n",
    "    birthday_col = df['birthday'].copy()\n",
    "    age = -round((birthday_col-datetime_temp)/np.timedelta64(1,'D')/30)\n",
    "    df['age'] = age\n",
    "    df.drop(columns=['birthday'], inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_occurrence_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>age_in_months</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthday_formatted</th>\n",
       "      <th>new_visit_startdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>475850426</td>\n",
       "      <td>558863894</td>\n",
       "      <td>0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>2024-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>1465362657</td>\n",
       "      <td>558863894</td>\n",
       "      <td>4</td>\n",
       "      <td>MALE</td>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>2024-09-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      visit_occurrence_id  person_id  age_in_months gender birthday_formatted  \\\n",
       "3262            475850426  558863894              0   MALE         2024-05-21   \n",
       "3263           1465362657  558863894              4   MALE         2024-05-21   \n",
       "\n",
       "     new_visit_startdate  \n",
       "3262          2024-05-21  \n",
       "3263          2024-09-12  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_2['person_demographics_episode_train'][training_data_2['person_demographics_episode_train']['person_id']==558863894]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>uid</th>\n",
       "      <th>Systolic blood pressure</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Body temperature</th>\n",
       "      <th>Respiratory rate</th>\n",
       "      <th>Heart rate</th>\n",
       "      <th>Measurement of oxygen saturation at periphery</th>\n",
       "      <th>Oxygen/Gas total [Pure volume fraction] Inhaled gas</th>\n",
       "      <th>Base excess in Venous blood by calculation</th>\n",
       "      <th>...</th>\n",
       "      <th>D-dimer level</th>\n",
       "      <th>Blood arterial pH</th>\n",
       "      <th>Hemoglobin [Moles/volume] in Blood</th>\n",
       "      <th>drugs</th>\n",
       "      <th>routes</th>\n",
       "      <th>visit_occurrence_id</th>\n",
       "      <th>procedure</th>\n",
       "      <th>new_person_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158419</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-25 22:00:001554848268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.762710</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>97.923730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cannulation</td>\n",
       "      <td>1554848268</td>\n",
       "      <td>MALE</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150622</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-07 19:00:00880100808</td>\n",
       "      <td>103.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>34.016808</td>\n",
       "      <td>138.470580</td>\n",
       "      <td>98.857140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cannulation</td>\n",
       "      <td>880100808</td>\n",
       "      <td>MALE</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286134</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-10 02:00:001319523270</td>\n",
       "      <td>86.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.907562</td>\n",
       "      <td>124.546220</td>\n",
       "      <td>94.588234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cannulation</td>\n",
       "      <td>1319523270</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193199</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-09 06:00:00286993525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>286993525</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212014</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-02 21:00:001533496055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-invasive ventilation</td>\n",
       "      <td>1533496055</td>\n",
       "      <td>MALE</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83526</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-29 04:00:00285203296</td>\n",
       "      <td>117.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.128570</td>\n",
       "      <td>98.685715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>285203296</td>\n",
       "      <td>MALE</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146815</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-09 08:00:0043078502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'milrinone'</td>\n",
       "      <td>'Intravenous'</td>\n",
       "      <td>902176928.0</td>\n",
       "      <td>Cannulation</td>\n",
       "      <td>43078502</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91116</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-17 19:00:00686567062</td>\n",
       "      <td>104.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>29.403362</td>\n",
       "      <td>124.411766</td>\n",
       "      <td>99.299150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cannulation</td>\n",
       "      <td>686567062</td>\n",
       "      <td>MALE</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113276</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-15 03:00:001664177375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cannulation</td>\n",
       "      <td>1664177375</td>\n",
       "      <td>MALE</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83524</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-17 05:00:001335786468</td>\n",
       "      <td>81.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>49.235294</td>\n",
       "      <td>142.201680</td>\n",
       "      <td>98.142860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1335786468</td>\n",
       "      <td>MALE</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SepsisLabel                            uid  Systolic blood pressure  \\\n",
       "158419            0  2024-04-25 22:00:001554848268                      NaN   \n",
       "150622            0   2023-12-07 19:00:00880100808                    103.0   \n",
       "286134            0  2024-02-10 02:00:001319523270                     86.0   \n",
       "193199            0   2023-06-09 06:00:00286993525                      NaN   \n",
       "212014            0  2019-10-02 21:00:001533496055                      NaN   \n",
       "83526             0   2024-04-29 04:00:00285203296                    117.0   \n",
       "146815            0    2023-01-09 08:00:0043078502                      NaN   \n",
       "91116             0   2024-09-17 19:00:00686567062                    104.0   \n",
       "113276            0  2021-11-15 03:00:001664177375                      NaN   \n",
       "83524             0  2024-09-17 05:00:001335786468                     81.0   \n",
       "\n",
       "        Diastolic blood pressure  Body temperature  Respiratory rate  \\\n",
       "158419                       NaN               NaN         70.762710   \n",
       "150622                      67.0              36.4         34.016808   \n",
       "286134                      31.0               NaN         32.907562   \n",
       "193199                       NaN              35.8               NaN   \n",
       "212014                       NaN              36.7               NaN   \n",
       "83526                       71.0               NaN               NaN   \n",
       "146815                       NaN               NaN               NaN   \n",
       "91116                       72.0              36.3         29.403362   \n",
       "113276                       NaN              36.3               NaN   \n",
       "83524                       42.0              36.4         49.235294   \n",
       "\n",
       "        Heart rate  Measurement of oxygen saturation at periphery  \\\n",
       "158419  164.000000                                      97.923730   \n",
       "150622  138.470580                                      98.857140   \n",
       "286134  124.546220                                      94.588234   \n",
       "193199         NaN                                            NaN   \n",
       "212014         NaN                                            NaN   \n",
       "83526    68.128570                                      98.685715   \n",
       "146815         NaN                                            NaN   \n",
       "91116   124.411766                                      99.299150   \n",
       "113276         NaN                                            NaN   \n",
       "83524   142.201680                                      98.142860   \n",
       "\n",
       "        Oxygen/Gas total [Pure volume fraction] Inhaled gas  \\\n",
       "158419                                                NaN     \n",
       "150622                                                NaN     \n",
       "286134                                                NaN     \n",
       "193199                                                NaN     \n",
       "212014                                                NaN     \n",
       "83526                                                 NaN     \n",
       "146815                                                NaN     \n",
       "91116                                                 NaN     \n",
       "113276                                                NaN     \n",
       "83524                                                 NaN     \n",
       "\n",
       "        Base excess in Venous blood by calculation  ...  D-dimer level  \\\n",
       "158419                                         NaN  ...            NaN   \n",
       "150622                                         NaN  ...            NaN   \n",
       "286134                                         NaN  ...            NaN   \n",
       "193199                                         3.7  ...            NaN   \n",
       "212014                                         NaN  ...            NaN   \n",
       "83526                                          NaN  ...            NaN   \n",
       "146815                                         NaN  ...            NaN   \n",
       "91116                                          NaN  ...            NaN   \n",
       "113276                                         NaN  ...            NaN   \n",
       "83524                                          NaN  ...            NaN   \n",
       "\n",
       "        Blood arterial pH  Hemoglobin [Moles/volume] in Blood        drugs  \\\n",
       "158419                NaN                                 NaN          NaN   \n",
       "150622                NaN                                 NaN          NaN   \n",
       "286134                NaN                                 NaN          NaN   \n",
       "193199               10.2                                1.18          NaN   \n",
       "212014                NaN                                 NaN          NaN   \n",
       "83526                 NaN                                 NaN          NaN   \n",
       "146815                NaN                                 NaN  'milrinone'   \n",
       "91116                 NaN                                 NaN          NaN   \n",
       "113276                NaN                                 NaN          NaN   \n",
       "83524                 NaN                                 NaN          NaN   \n",
       "\n",
       "               routes  visit_occurrence_id                 procedure  \\\n",
       "158419            NaN                  NaN               Cannulation   \n",
       "150622            NaN                  NaN               Cannulation   \n",
       "286134            NaN                  NaN               Cannulation   \n",
       "193199            NaN                  NaN                       NaN   \n",
       "212014            NaN                  NaN  Non-invasive ventilation   \n",
       "83526             NaN                  NaN                       NaN   \n",
       "146815  'Intravenous'          902176928.0               Cannulation   \n",
       "91116             NaN                  NaN               Cannulation   \n",
       "113276            NaN                  NaN               Cannulation   \n",
       "83524             NaN                  NaN                       NaN   \n",
       "\n",
       "        new_person_id  gender    age  \n",
       "158419     1554848268    MALE    4.0  \n",
       "150622      880100808    MALE   12.0  \n",
       "286134     1319523270  FEMALE    9.0  \n",
       "193199      286993525  FEMALE    9.0  \n",
       "212014     1533496055    MALE    1.0  \n",
       "83526       285203296    MALE  127.0  \n",
       "146815       43078502  FEMALE    0.0  \n",
       "91116       686567062    MALE    7.0  \n",
       "113276     1664177375    MALE    4.0  \n",
       "83524      1335786468    MALE    4.0  \n",
       "\n",
       "[10 rows x 52 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_factors_2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factors_2 = birthday_ubiquity(df = data_factors_2, data_dictionary = training_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 324753, 1: 6874})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data_factors_2['SepsisLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factors_3 = data_factors_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'drugs', 'routes', 'procedure', 'gender'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_factors_3.select_dtypes(object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factors_3.drop(columns=['visit_occurrence_id','uid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_encoding(df: pd.DataFrame):\n",
    "    categorical_cols = list(df.select_dtypes(object).columns)\n",
    "    le_dictionary = {}\n",
    "    for name in tqdm(categorical_cols):\n",
    "        print(name)\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df.loc[:,f'{name}'])\n",
    "        new_col = le.transform(df.loc[:,f'{name}'])\n",
    "        le_dictionary[name] = le\n",
    "        df.drop(columns=f'{name}', inplace=True)\n",
    "        df[f'new_{name}'] = new_col\n",
    "        print(f'finished {name}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:00<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drugs\n",
      "finished drugs\n",
      "routes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished routes\n",
      "procedure\n",
      "finished procedure\n",
      "gender\n",
      "finished gender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_encoding(data_factors_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_factors_3.select_dtypes(object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SepsisLabel', 'Systolic blood pressure',\n",
       "       'Diastolic blood pressure', 'Body temperature', 'Respiratory rate',\n",
       "       'Heart rate', 'Measurement of oxygen saturation at periphery',\n",
       "       'Oxygen/Gas total [Pure volume fraction] Inhaled gas',\n",
       "       'Base excess in Venous blood by calculation',\n",
       "       'Base excess in Arterial blood by calculation',\n",
       "       'Phosphate [Moles/volume] in Serum or Plasma',\n",
       "       'Potassium [Moles/volume] in Blood',\n",
       "       'Bilirubin.total [Moles/volume] in Serum or Plasma',\n",
       "       'Neutrophil Ab [Units/volume] in Serum',\n",
       "       'Bicarbonate [Moles/volume] in Arterial blood',\n",
       "       'Hematocrit [Volume Fraction] of Blood',\n",
       "       'Glucose [Moles/volume] in Serum or Plasma',\n",
       "       'Calcium [Moles/volume] in Serum or Plasma',\n",
       "       'Chloride [Moles/volume] in Blood',\n",
       "       'Sodium [Moles/volume] in Serum or Plasma',\n",
       "       'C reactive protein [Mass/volume] in Serum or Plasma',\n",
       "       'Carbon dioxide [Partial pressure] in Venous blood',\n",
       "       'Oxygen [Partial pressure] in Venous blood',\n",
       "       'Albumin [Mass/volume] in Serum or Plasma',\n",
       "       'Bicarbonate [Moles/volume] in Venous blood',\n",
       "       'Oxygen [Partial pressure] in Arterial blood',\n",
       "       'Carbon dioxide [Partial pressure] in Arterial blood',\n",
       "       'Interleukin 6 [Mass/volume] in Body fluid',\n",
       "       'Magnesium [Moles/volume] in Blood', 'Prothrombin time (PT)',\n",
       "       'Procalcitonin [Mass/volume] in Serum or Plasma',\n",
       "       'Lactate [Moles/volume] in Blood',\n",
       "       'Creatinine [Mass/volume] in Blood', 'Fibrinogen measurement',\n",
       "       'Bilirubin measurement', 'Partial thromboplastin time',\n",
       "       ' activated', 'Total white blood count', 'Platelet count',\n",
       "       'White blood cell count', 'Blood venous pH', 'D-dimer level',\n",
       "       'Blood arterial pH', 'Hemoglobin [Moles/volume] in Blood',\n",
       "       'new_person_id', 'age', 'new_drugs', 'new_routes', 'new_procedure',\n",
       "       'new_gender'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_factors_3.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_modeling(df):\n",
    "    column_list = []\n",
    "    [column_list.append(i) for i in range(1,44)]\n",
    "    [column_list.append(i) for i in range(45,50)]\n",
    "    X = df.iloc[:,column_list].values\n",
    "    y = df.iloc[:,0].values\n",
    "    person_id = df.iloc[:,44].values\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2)\n",
    "    for train_x_index, test_x_index in gss.split(X=X,y=y,groups=person_id):\n",
    "        X_train = X[train_x_index]\n",
    "        X_test = X[test_x_index]\n",
    "        y_train = y[train_x_index]\n",
    "        y_test = y[test_x_index]\n",
    "        person_id_train = person_id[train_x_index]\n",
    "        person_id_test = person_id[test_x_index]\n",
    "        \n",
    "    formatted_data = {}\n",
    "    formatted_data['X_train'] = X_train\n",
    "    formatted_data['X_test'] = X_test\n",
    "    formatted_data['y_train'] = y_train\n",
    "    formatted_data['y_test'] = y_test\n",
    "    formatted_data['person_id_train'] = person_id_train\n",
    "    formatted_data['person_id_test'] = person_id_test\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = format_for_modeling(data_factors_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_model(data_dictionary: dict):\n",
    "    X_train = data_dictionary['X_train']\n",
    "    X_test = data_dictionary['X_test']\n",
    "    y_train = data_dictionary['y_train']\n",
    "    y_test = data_dictionary['y_test']\n",
    "    person_id_train = data_dictionary['person_id_train']\n",
    "    person_id_test = data_dictionary['person_id_test']\n",
    "\n",
    "    r_forest_model = RandomForestClassifier()\n",
    "    r_forest_model.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = r_forest_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy score: {accuracy}\")\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    print(f\"F1 score: {f1}\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=['not sepsis', 'sepsis'], yticklabels=['not sepsis', 'sepsis'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show(block=False)\n",
    "    return r_forest_model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9804965774909035\n",
      "F1 score: 0.07778510217534608\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest, preds = forest_model(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 19.0 MiB for an array with shape (51979, 48) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 16\u001b[0m\n\u001b[0;32m      7\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m { \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m300\u001b[39m], \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m], \n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m30\u001b[39m], \n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_leaf_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m9\u001b[39m], \n\u001b[0;32m     12\u001b[0m } \n\u001b[0;32m     14\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(RandomForestClassifier(), \n\u001b[0;32m     15\u001b[0m \t\t\t\t\t\tparam_grid\u001b[38;5;241m=\u001b[39mparam_grid) \n\u001b[1;32m---> 16\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_) \n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    885\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    887\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[1;32m--> 888\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43m_safe_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:158\u001b[0m, in \u001b[0;36m_safe_split\u001b[1;34m(estimator, X, y, indices, train_indices)\u001b[0m\n\u001b[0;32m    156\u001b[0m         X_subset \u001b[38;5;241m=\u001b[39m X[np\u001b[38;5;241m.\u001b[39mix_(indices, train_indices)]\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     X_subset \u001b[38;5;241m=\u001b[39m \u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     y_subset \u001b[38;5;241m=\u001b[39m _safe_indexing(y, indices)\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:411\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32mc:\\Users\\pears\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:208\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    207\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 19.0 MiB for an array with shape (51979, 48) and data type float64"
     ]
    }
   ],
   "source": [
    "X_train = split_data['X_train']\n",
    "X_test = split_data['X_test']\n",
    "y_train = split_data['y_train']\n",
    "y_test = split_data['y_test']\n",
    "\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 150, 300], \n",
    "    'max_features': ['sqrt', 'log2', None], \n",
    "    'max_depth': [10, 15, 30], \n",
    "    'max_leaf_nodes': [3, 6, 9], \n",
    "} \n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), \n",
    "\t\t\t\t\t\tparam_grid=param_grid) \n",
    "grid_search.fit(X_train, y_train) \n",
    "print(grid_search.best_estimator_) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
