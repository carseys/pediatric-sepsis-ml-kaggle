{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readin_data(data_type: str):\n",
    "    \"\"\" This function reads in test or train data, which must be in folders 'testing_data' and 'training_data' in the same directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_type' : str\n",
    "        This must be 'test' or 'train'.\n",
    "    \"\"\"\n",
    "    assert (data_type=='test') or (data_type=='train'), f'You gave data_type as {data_type}. Please define data_type as \"test\" or \"train.\"'\n",
    "    if data_type == 'test':\n",
    "        inner_directory = './testing_data/'\n",
    "        data_list = os.listdir('./testing_data')\n",
    "    else:\n",
    "        inner_directory = './training_data/'\n",
    "        data_list = os.listdir('./training_data')\n",
    "    data_dict = {}\n",
    "    for file_name in data_list:\n",
    "        data_dict[file_name.split('.')[0]] = pd.read_csv(inner_directory+file_name).drop_duplicates()\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('./processed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_uids(data_dictionary: dict):\n",
    "    \"\"\" This function adds a UID to each row to establish unique instances between person_id & measurement datetimes for the various tables.\n",
    "    \n",
    "    This is not done for the demographics file since the information in it is not sensitive to the hour.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    for table_ind in list(data_dictionary.keys()):\n",
    "        if not table_ind.startswith(\"person_demographics\"):\n",
    "            table = data_dictionary[table_ind]\n",
    "            datetime_index = np.argmax([i.find('datetime') for i in table.columns])\n",
    "            date_column = table.columns[datetime_index]\n",
    "            personid_index = np.argmax([i.find('person_id') for i in table.columns])\n",
    "            personid_column = table.columns[personid_index]\n",
    "            table['uid'] = table[date_column].astype(str) + table[personid_column].astype(str)\n",
    "            table.drop(columns=[date_column,personid_column],inplace=True)\n",
    "            data_dictionary[table_ind] = table\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birthday_management(data_dictionary: dict):\n",
    "    \"\"\"\n",
    "    This function processes the 'person_demographics' table of given data, which is inputed as a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    demographics_ind_no = np.argmax([table.startswith(\"person_demographics\") for table in data_dictionary.keys()])\n",
    "    demographics_index = list(data_dictionary.keys())[demographics_ind_no]\n",
    "    demographics = data_dictionary[demographics_index]\n",
    "\n",
    "    new_birthday_col = pd.DataFrame(columns=['birthday_formatted', 'person_id'])\n",
    "    new_visit_col = pd.DataFrame(columns=['visit_start_date','new_visit_startdate'])\n",
    "    \n",
    "    for person in np.unique(demographics['person_id']):\n",
    "        birthday = demographics[demographics['person_id']==person]['birth_datetime'].to_list()[0]\n",
    "        birthday_formatted = datetime.strptime(birthday,'%Y-%m-%d')\n",
    "        new_birthday_col.loc[len(new_birthday_col)] = [birthday_formatted, person]\n",
    "\n",
    "    for date in np.unique(demographics['visit_start_date']):\n",
    "        visit_start = demographics[demographics['visit_start_date']==date]['visit_start_date'].to_list()[0]\n",
    "        new_visit_startdate = datetime.strptime(visit_start,'%Y-%m-%d')\n",
    "        # print(f'new {new_visit_startdate} old {date}')\n",
    "        new_visit_col.loc[len(new_visit_col)] = [date, new_visit_startdate]\n",
    "\n",
    "\n",
    "    demographics = pd.merge(left=demographics,right=new_birthday_col,how='left',on='person_id')\n",
    "    demographics = pd.merge(left=demographics,right=new_visit_col,how='left',on='visit_start_date')\n",
    "    demographics.drop(columns=['visit_start_date','birth_datetime'],inplace=True)\n",
    "    demographics.to_csv(f'./processed_data/processed_{demographics_index}.csv')\n",
    "    data_dictionary[demographics_index] = demographics\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_meds_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'measurement_meds' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    body_measurements_ind = np.argmax([table.startswith(\"measurement_meds\") for table in data_dictionary.keys()])\n",
    "    body_measurements_index = list(data_dictionary.keys())[body_measurements_ind]\n",
    "    measurements = data_dictionary[body_measurements_index]\n",
    "    \n",
    "    measurements = measurements.dropna(subset=measurements.select_dtypes(float).columns, how='all')\n",
    "    # measurements.drop(index=[i for i in measurements[measurements['Body temperature']>45].index], axis=1,inplace=True)\n",
    "    measurements['Body temperature'] = measurements['Body temperature'].apply(lambda x: np.nan if x >46 else x)\n",
    "    measurements.to_csv(f'./processed_data/processed_{body_measurements_index}.csv')\n",
    "    data_dictionary[body_measurements_index] = measurements\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDONE NOT TESTED\n",
    "\n",
    "def drugs_exposure_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'drugsexposure' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    You need to run add_uids first.\n",
    "    \"\"\"\n",
    "    # assert uids_added == True, 'You need to run add_uids before this function.'\n",
    "    drugs_exposure_ind = np.argmax([table.startswith(\"drugsexposure\") for table in data_dictionary.keys()])\n",
    "    drugs_exposure_index = list(data_dictionary.keys())[drugs_exposure_ind]\n",
    "    drugs_exposure = data_dictionary[drugs_exposure_index]\n",
    "\n",
    "    drugs_exposure_processed = pd.DataFrame(columns = ['uid', 'drugs', 'routes', 'visit_occurrence_id'])\n",
    "    for x in tqdm(np.unique(drugs_exposure['uid'])):\n",
    "        drugs = drugs_exposure[drugs_exposure['uid']==x]['drug_concept_id'].to_list()\n",
    "        drugs.sort()\n",
    "        try:\n",
    "            route = drugs_exposure[drugs_exposure['uid']==x]['route_concept_id'].to_list()\n",
    "            route = list(set(route))\n",
    "            route = [str(i) for i in route]\n",
    "            route.sort()\n",
    "        except:\n",
    "            route = drugs_exposure[drugs_exposure['uid']==x]['route_concept_id'].to_list()\n",
    "            route = list(set(route))\n",
    "        visit_occurrence = drugs_exposure[drugs_exposure['uid']==x]['visit_occurrence_id'].to_list()[0]\n",
    "        drugs_exposure_processed.loc[len(drugs_exposure_processed)]= [x,drugs,route, visit_occurrence]\n",
    "    data_dictionary[drugs_exposure_index] = drugs_exposure_processed\n",
    "    drugs_exposure.to_csv(f'./processed_data/processed_{drugs_exposure_index}.csv')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_lab_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'measurement_lab' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    You need to run add_uids first.\n",
    "    \"\"\"\n",
    "    # assert uids_added == True, 'You need to run add_uids before this function.'\n",
    "\n",
    "    measurement_lab_ind = np.argmax([table.startswith(\"measurement_lab\") for table in data_dictionary.keys()])\n",
    "    measurement_lab_index = list(data_dictionary.keys())[measurement_lab_ind]\n",
    "    measurement_lab = data_dictionary[measurement_lab_index]\n",
    "\n",
    "    measurement_lab = measurement_lab.dropna(subset=measurement_lab.select_dtypes(float).columns, how='all')\n",
    "    measurement_lab_count = pd.DataFrame([list(i) for i in Counter(measurement_lab['uid']).items()],columns=['uid','count'])\n",
    "    measurement_lab_count['count'].astype(int)\n",
    "    measurement_lab_rows = pd.DataFrame()\n",
    "    measurement_lab_extras = measurement_lab_count[measurement_lab_count['count']>1]\n",
    "    for j in [i for i in measurement_lab_extras['uid']]:\n",
    "        measurement_lab_rows = pd.concat([measurement_lab_rows,measurement_lab[measurement_lab['uid']==j].max().to_frame().T]).reset_index(drop=True)\n",
    "    measurement_lab.drop(index=[i for i in measurement_lab[measurement_lab['uid']==measurement_lab_extras['uid'].item()].index], axis=1,inplace=True)\n",
    "    measurement_lab = pd.concat([measurement_lab,measurement_lab_rows]).reset_index(drop=True)\n",
    "\n",
    "    measurement_lab.to_csv(f'./processed_data/processed_{measurement_lab_index}.csv')\n",
    "    data_dictionary[measurement_lab_index] = measurement_lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_observation_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'measurement_observation' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    measurement_obs_ind = np.argmax([table.startswith(\"measurement_observation\") for table in data_dictionary.keys()])\n",
    "    measurement_obs_index = list(data_dictionary.keys())[measurement_obs_ind]\n",
    "    measurement_obs = data_dictionary[measurement_obs_index]\n",
    "\n",
    "    # measurement_obs = measurement_obs.dropna(subset=measurement_obs.select_dtypes(float).columns, how='all')\n",
    "    measurement_obs.to_csv(f'./processed_data/processed_{measurement_obs_index}.csv')\n",
    "    data_dictionary[measurement_obs_index] = measurement_obs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'observation' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    observation_ind = np.argmax([table.startswith(\"observation\") for table in data_dictionary.keys()])\n",
    "    observation_index = list(data_dictionary.keys())[observation_ind]\n",
    "    observation = data_dictionary[observation_index]\n",
    "\n",
    "    observation = observation.dropna(subset=observation.select_dtypes(object).columns, how='all')\n",
    "\n",
    "    observation.to_csv(f'./processed_data/processed_{observation_index}.csv')\n",
    "\n",
    "    data_dictionary[observation_index] = observation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedures_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'observation' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    You need to run add_uids first.\n",
    "    \"\"\"\n",
    "    # assert uids_added == True, 'You need to run add_uids before this function.'\n",
    "\n",
    "    procedures_ind = np.argmax([table.startswith(\"proceduresoccurrences\") for table in data_dictionary.keys()])\n",
    "    procedures_index = list(data_dictionary.keys())[procedures_ind]\n",
    "    procedures = data_dictionary[procedures_index]\n",
    "\n",
    "    procedures = procedures.dropna(subset=procedures.select_dtypes(object).columns, how='all')\n",
    "\n",
    "\n",
    "    visit_id_index = np.argmax([i.find('visit_occurrence') for i in procedures.columns])\n",
    "    visit_column = procedures.columns[visit_id_index]\n",
    "    procedures.drop(columns=visit_column,inplace=True)\n",
    "    procedures.drop_duplicates(inplace=True)\n",
    "\n",
    "    procedures.to_csv(f'./processed_data/processed_{procedures_index}.csv')\n",
    "\n",
    "\n",
    "    data_dictionary[procedures_index] = procedures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devices_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'devices' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    devices_ind = np.argmax([table.startswith(\"devices\") for table in data_dictionary.keys()])\n",
    "    devices_index = list(data_dictionary.keys())[devices_ind]\n",
    "    devices = data_dictionary[devices_index]\n",
    "\n",
    "    devices = devices.dropna(subset=devices.select_dtypes(object).columns, how='all')\n",
    "\n",
    "    devices.to_csv(f'./processed_data/processed_{devices_index}.csv')\n",
    "\n",
    "    data_dictionary[devices_index] = devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepsis_processing(data_dictionary: dict):\n",
    "    \"\"\" This function processes the 'sepsis' table of given data, which is inputed in a dictionary. The data in dictionary is replaced by index, hence function returns nothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_dictionary' : dict\n",
    "        A dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    sepsis_ind = np.argmax([table.startswith(\"SepsisLabel\") for table in data_dictionary.keys()])\n",
    "    sepsis_index = list(data_dictionary.keys())[sepsis_ind]\n",
    "    sepsis = data_dictionary[sepsis_index]\n",
    "\n",
    "    #no NA values found:\n",
    "    sepsis = sepsis.dropna(subset=sepsis.select_dtypes(int).columns, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_type: str):\n",
    "    \"\"\" This function reads in test or train data and goes through functions to preprocess it. For further details see specific functions.\n",
    "\n",
    "    If processing has already been run then files from the 'processed_data' folder will be loaded instead of reprocessing.\n",
    "\n",
    "    Returns factors, a DataFrame of processed data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    'data_type' : str\n",
    "        This must be 'test' or 'train'.\n",
    "    \"\"\"\n",
    "    assert (data_type=='test') or (data_type=='train'), f'You gave data_type as {data_type}. Please define data_type as \"test\" or \"train.\"'\n",
    "\n",
    "    if data_type == 'train':\n",
    "        training_data = readin_data('train')\n",
    "        add_uids(training_data)\n",
    "        birthday_management(training_data)\n",
    "        measurement_meds_processing(training_data)\n",
    "        drugs_exposure_processing(training_data)\n",
    "        measurement_lab_processing(training_data)\n",
    "        procedures_processing(training_data)\n",
    "\n",
    "        factors = pd.merge(left=training_data['measurement_meds_train'], right=training_data['measurement_lab_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['drugsexposure_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['proceduresoccurrences_train'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=training_data['person_demographics_episode_train'], how='outer',on='visit_occurrence_id')\n",
    "        factors = pd.merge(left=training_data['SepsisLabel_train'],right=factors,how='left',on='uid')\n",
    "\n",
    "    else:\n",
    "        testing_data = readin_data('test')\n",
    "        add_uids(testing_data)\n",
    "        birthday_management(testing_data)\n",
    "        measurement_meds_processing(testing_data)\n",
    "        drugs_exposure_processing(testing_data)\n",
    "        measurement_lab_processing(testing_data)\n",
    "\n",
    "        factors = pd.merge(left=testing_data['measurement_meds_test'], right=testing_data['measurement_lab_test'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=testing_data['drugsexposure_test'],how='outer',on='uid')\n",
    "        factors = pd.merge(left=factors, right=testing_data['person_demographics_episode_test'], how='outer',on='visit_occurrence_id')\n",
    "        factors = pd.merge(left=testing_data['SepsisLabel_test'],right=factors,how='left',on='uid')\n",
    "\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 4636/150407 [02:52<1:29:52, 27.03it/s]"
     ]
    }
   ],
   "source": [
    "process_data('train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
